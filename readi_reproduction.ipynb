{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nicolashernandez/READI-LREC22/blob/main/readi_reproduction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook comes from the git repository available [here](https://github.com/nicolashernandez/READI-LREC22/)  \n",
    "The following examples will show how this library can be used and configured.  \n",
    "It'll later be ported to colab, this is a version that works on your computer as long as the library has been installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup, ignore this if the library is already installed on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once we convert to colab or something online, we should apparently do something like this\n",
    "#!git clone https://github.com/nicolashernandez/READI-LREC22/\n",
    "#sys.path.insert(0,'/content/READI-LREC22')\n",
    "#from ..... import readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"readability\"))\n",
    "#sys.path.pop()\n",
    "#sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#FIXME : replace this with a wget to the git directory\n",
    "with open(os.path.join(os.getcwd(),\"data\",\"tokens_split.pkl\"), \"rb\") as file:\n",
    "    corpus = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example one : Using the library for a text\n",
    "\n",
    "Texts can be strings, but it is preferred to prepare them beforehand as tokenized sentences. ( list(list()) )  \n",
    "If using spacy, something like this can be used :  \n",
    "new_text = [[token.text for token in sent] for sent in spacy(text).sents]  \n",
    "And to remove punctuation marks, this can be done instead :  \n",
    "new_text = [[token.text for token in sent if not token.is_punct] for sent in spacy(temp).sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'readability' from '/home/stagiaire-taln/Stage_repo_git/READI-LREC22/library/readability/__init__.py'>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(readability.readability)\n",
    "importlib.reload(readability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A readability instance is created by calling readability.Readability(text)  \n",
    "The following arguments are optional : lang, nlp_name, perplexity_processor  \n",
    "By default, this instance will use the french language, by using a spacy_sm nlp processor, and gpt2 for processing perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG : Current parameters of Readability class : lang= fr nlp= spacy_sm ppl_processor= gpt2\n",
      "Acquiring Natural Language Processor...\n",
      "DEBUG: Spacy model location (already installed) :  /home/stagiaire-taln/anaconda3/lib/python3.9/site-packages/fr_core_news_sm/fr_core_news_sm-3.3.0\n",
      "DEBUG : Text recognized as list of sentences, not converting\n",
      "DEBUG: recognized content is : [[\"Aujourd'hui\", ',', 'toute', 'la', 'famille', 'est', 'allée', 'à', 'la', 'fête', 'foraine', '.'], ['Papa', 'a', 'acheté', 'à', 'mon', 'frère', 'des', 'lunettes', 'amusantes', '.'], ['Maman', \"m'\", 'a', 'acheté', 'une', 'très', 'belle', 'casquette', 'bleue', '.'], ['Ma', 'petite', 'sœur', ',', 'elle', ',', 'a', 'eu', 'un', 'suçon', '.'], ['En', 'revenant', 'à', 'la', 'maison', ',', 'un', 'très', 'gros', 'coup', 'de', 'vent', 'a', 'emporté', 'ma', 'casquette', '.'], ['Ma', 'casquette', 'est', 'allée', 'se', 'poser', 'sur', 'la', 'branche', \"d'\", 'un', 'vieil', 'arbre', 'énorme', '.'], [\"J'\", 'ai', 'beaucoup', 'pleuré', '.'], [\"J'\", 'ai', 'même', 'refusé', 'de', 'manger', 'pour', 'le', 'souper', '.'], ['Plus', 'tard', 'en', 'soirée', ',', 'la', 'lune', 'a', 'fait', 'son', 'apparition', '.'], [\"J'\", 'avais', \"l'\", 'impression', \"qu'\", 'elle', 'regardait', 'ma', 'casquette', 'dans', 'le', 'vieil', 'arbre', '.'], ['La', 'lune', 'a', 'essayé', 'ma', 'casquette', 'et', 'elle', 'a', 'souri', '.'], [\"J'\", 'ai', 'souri', 'aussi', '.'], ['Le', 'lendemain', ',', 'au', 'retour', 'de', \"l'\", 'école', ',', 'ma', 'mère', \"m'\", 'a', 'donné', 'une', 'nouvelle', 'casquette', ',', 'mais', 'rouge', '.'], ['Elle', 'était', 'magnifique', '!', '\"'], ['La', 'lune', \"t'\", 'a', 'envoyé', \"t'\", 'a', 'envoyé', 'ceci', '.'], [\"m'\", 'a', '-', 't', '-', 'elle', 'dit', '.'], ['Ce', 'soir', '-', 'là', ',', 'je', 'suis', 'sorti', 'avec', 'ma', 'nouvelle', 'casquette', '.'], ['La', 'lune', 'était', 'là', ',', 'coiffée', 'de', 'ma', 'casquette', 'bleue', '.'], [\"J'\", 'étais', 'heureux', '.'], ['Est', '-ce', 'que', 'tu', 'crois', 'que', 'le', 'soleil', 'aurait', 'besoin', \"d'\", 'une', 'casquette', 'lui', 'aussi', '?'], ['Essaie', 'de', 'deviner', 'le', 'chapeau', 'que', 'je', 'porte', 'aujourd’hui', '!']]\n"
     ]
    }
   ],
   "source": [
    "#Types of available formats for a text:\n",
    "r = readability.Readability(corpus['level1'][0]) # A text in the list(list()) format used internally\n",
    "#r = readability.Readability(' '.join(corpus['level1'][0][0])) # A string, it will be converted into a list(list()), of size 1, with 12 tokens, including punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common scores can be accessed by using the corresponding function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG : pre-existing information was not found, so the .gfi_score() function should determine it by itself\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61.52380952380953"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfi = r.gfi()\n",
    "gfi #is 61.52380952380953"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More conveniently, a list of these scores can be obtained by using .scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG : pre-existing information was not found, so the .gfi_score() function should determine it by itself\n",
      "DEBUG : pre-existing information was not found, so the .ari_score() function should determine it by itself\n",
      "DEBUG : pre-existing information was not found, so the .fre_score() function should determine it by itself\n",
      "DEBUG : pre-existing information was not found, so the .fkgl_score() function should determine it by itself\n",
      "DEBUG : pre-existing information was not found, so the .smog_score() function should determine it by itself\n",
      "DEBUG : pre-existing information was not found, so the .rel_score() function should determine it by itself\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gfi': 61.52380952380953,\n",
       " 'ari': 21.503161490683233,\n",
       " 'fre': 54.47311594202901,\n",
       " 'fkgl': 8.382298136645964,\n",
       " 'smog': 13.023866798666859,\n",
       " 'rel': 73.00333333333334}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to speed the calculations needed by these functions, the .compile() function can be used.  \n",
    "It calculates most of the statistics needed for a text, and puts it in the .statistics attribute of the Readability object.  \n",
    "These can be viewed by doing .stats(), or directly accessing the .statistics attribute.  \n",
    "For example : .statistics.totalWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalWords  =  230\n",
      "totalLongWords  =  30\n",
      "totalSentences  =  21\n",
      "totalCharacters  =  837\n",
      "totalSyllables  =  384\n",
      "nbPolysyllables  =  63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.compile()\n",
    "r.stats()\n",
    "r.statistics.totalWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example two : Using the library for a corpus\n",
    "\n",
    "Currently, a corpus will be recognized by the library only if provided with the following structure :  \n",
    "type(corpus) = dict[class][text][sentence][token]  \n",
    "For instance, corpA['class1'][0][0][0] should return the first token of the first sentence of the first text of class 'class1', for the corpus 'corpA'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG : Current parameters of Readability class : lang= fr nlp= spacy_sm ppl_processor= gpt2\n",
      "Acquiring Natural Language Processor...\n",
      "DEBUG: Spacy model location (already installed) :  /home/stagiaire-taln/anaconda3/lib/python3.9/site-packages/fr_core_news_sm/fr_core_news_sm-3.3.0\n",
      "DEBUG : recognized as corpus\n"
     ]
    }
   ],
   "source": [
    "r = readability.Readability(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful function resuming the contents of the corpus is available, called .corpus_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "      <th>level4</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nombre de fichiers</th>\n",
       "      <td>240.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>2060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nombre de phrases total</th>\n",
       "      <td>4880.0</td>\n",
       "      <td>13049.0</td>\n",
       "      <td>10354.0</td>\n",
       "      <td>7743.0</td>\n",
       "      <td>36026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nombre de phrases moyen</th>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longueur moyenne de phrase</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nombre de tokens</th>\n",
       "      <td>38976.0</td>\n",
       "      <td>128019.0</td>\n",
       "      <td>124901.0</td>\n",
       "      <td>101165.0</td>\n",
       "      <td>393061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nombre de token moyen</th>\n",
       "      <td>162.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taille du vocabulaire</th>\n",
       "      <td>4836.0</td>\n",
       "      <td>10903.0</td>\n",
       "      <td>11953.0</td>\n",
       "      <td>11410.0</td>\n",
       "      <td>23100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taille moyenne du vocabulaire</th>\n",
       "      <td>99.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>2257.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                level1    level2    level3    level4     total\n",
       "Nombre de fichiers               240.0     628.0     670.0     522.0    2060.0\n",
       "Nombre de phrases total         4880.0   13049.0   10354.0    7743.0   36026.0\n",
       "Nombre de phrases moyen           20.0      21.0      15.0      15.0      17.0\n",
       "Longueur moyenne de phrase         8.0      10.0      12.0      13.0      11.0\n",
       "Nombre de tokens               38976.0  128019.0  124901.0  101165.0  393061.0\n",
       "Nombre de token moyen            162.0     204.0     186.0     194.0     191.0\n",
       "Taille du vocabulaire           4836.0   10903.0   11953.0   11410.0   23100.0\n",
       "Taille moyenne du vocabulaire     99.0     130.0     127.0     149.0    2257.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.corpus_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using a corpus, the Readability object's methods can return different types of results, but the behavior is similar:  \n",
    "Instead of returning a value, or a list, the methods may return them in a dict[class][text_index] format.  \n",
    "Additionally, .compile() will create the .corpus_statistics attribute instead of .statistics.  \n",
    ".stats() will print the statistics of the first text in each class, in addition to showing the mean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish r.compile() first\n",
      "Class level1\n",
      "totalWords  =  230\n",
      "Class level1\n",
      "totalLongWords  =  30\n",
      "Class level1\n",
      "totalSentences  =  21\n",
      "Class level1\n",
      "totalCharacters  =  837\n",
      "Class level1\n",
      "totalSyllables  =  384\n",
      "Class level1\n",
      "nbPolysyllables  =  63\n",
      "Class level2\n",
      "totalWords  =  138\n",
      "Class level2\n",
      "totalLongWords  =  26\n",
      "Class level2\n",
      "totalSentences  =  8\n",
      "Class level2\n",
      "totalCharacters  =  555\n",
      "Class level2\n",
      "totalSyllables  =  240\n",
      "Class level2\n",
      "nbPolysyllables  =  43\n",
      "Class level3\n",
      "totalWords  =  104\n",
      "Class level3\n",
      "totalLongWords  =  16\n",
      "Class level3\n",
      "totalSentences  =  11\n",
      "Class level3\n",
      "totalCharacters  =  405\n",
      "Class level3\n",
      "totalSyllables  =  184\n",
      "Class level3\n",
      "nbPolysyllables  =  21\n",
      "Class level4\n",
      "totalWords  =  567\n",
      "Class level4\n",
      "totalLongWords  =  112\n",
      "Class level4\n",
      "totalSentences  =  35\n",
      "Class level4\n",
      "totalCharacters  =  2307\n",
      "Class level4\n",
      "totalSyllables  =  972\n",
      "Class level4\n",
      "nbPolysyllables  =  151\n"
     ]
    }
   ],
   "source": [
    "r.compile()\n",
    "r.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG : pre-existing information was found for a corpus\n",
      "DEBUG : pre-existing information was found for a corpus\n",
      "DEBUG : pre-existing information was found for a corpus\n",
      "DEBUG : pre-existing information was found for a corpus\n",
      "class level1 text 0 score 61.52380952380953\n",
      "class level2 text 0 score 136.9\n",
      "class level3 text 0 score 61.963636363636375\n",
      "class level4 text 0 score 134.48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61.52380952380953"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfi_corp = r.gfi()\n",
    "gfi_corp['level1'][0] #Is also 61.52380952380953"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r.scores behaves differently, instead of giving the scores for each text, it returns a dataframe showing the mean values, (and prints out the standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG : pre-existing information was found for a corpus\n",
      "Mean values                                 level1     level2     level3  \\\n",
      "The Gunning fog index GFI                45.132518  67.697721  91.866336   \n",
      "The Automated readability index ARI      14.238996  19.932585  25.719148   \n",
      "The Flesch reading ease FRE              90.625507  84.875840  82.799719   \n",
      "The Flesch-Kincaid grade level FKGL       4.576800   6.681592   8.323094   \n",
      "The Simple Measure of Gobbledygook SMOG  10.110286  11.521299  12.760749   \n",
      "Reading Ease Level                       92.465376  82.239781  75.110005   \n",
      "\n",
      "Mean values                                  level4  Pearson Score  \n",
      "The Gunning fog index GFI                105.669951       0.475915  \n",
      "The Automated readability index ARI       27.757700       0.472037  \n",
      "The Flesch reading ease FRE               81.032160      -0.402143  \n",
      "The Flesch-Kincaid grade level FKGL        9.019000       0.451786  \n",
      "The Simple Measure of Gobbledygook SMOG   13.210278       0.471106  \n",
      "Reading Ease Level                        71.711107      -0.408414  \n",
      "Standard Deviation values                   level1     level2     level3  \\\n",
      "The Gunning fog index GFI                22.638448  28.598931  38.724814   \n",
      "The Automated readability index ARI       6.265479   6.977522   8.614690   \n",
      "The Flesch reading ease FRE              26.013539  24.790444  29.308209   \n",
      "The Flesch-Kincaid grade level FKGL       3.386159   2.447647   2.501191   \n",
      "The Simple Measure of Gobbledygook SMOG   1.728092   1.647957   1.839104   \n",
      "Reading Ease Level                       19.108738  12.993784  12.457079   \n",
      "\n",
      "Standard Deviation values                   level4  \n",
      "The Gunning fog index GFI                45.192761  \n",
      "The Automated readability index ARI       9.156945  \n",
      "The Flesch reading ease FRE              32.117630  \n",
      "The Flesch-Kincaid grade level FKGL       2.833996  \n",
      "The Simple Measure of Gobbledygook SMOG   1.978900  \n",
      "Reading Ease Level                       14.318104  \n",
      "DEBUG: time elapsed perf counter: 0.025936164001905126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Mean values</th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "      <th>level4</th>\n",
       "      <th>Pearson Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The Gunning fog index GFI</th>\n",
       "      <td>45.132518</td>\n",
       "      <td>67.697721</td>\n",
       "      <td>91.866336</td>\n",
       "      <td>105.669951</td>\n",
       "      <td>0.475915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Automated readability index ARI</th>\n",
       "      <td>14.238996</td>\n",
       "      <td>19.932585</td>\n",
       "      <td>25.719148</td>\n",
       "      <td>27.757700</td>\n",
       "      <td>0.472037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Flesch reading ease FRE</th>\n",
       "      <td>90.625507</td>\n",
       "      <td>84.875840</td>\n",
       "      <td>82.799719</td>\n",
       "      <td>81.032160</td>\n",
       "      <td>-0.402143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Flesch-Kincaid grade level FKGL</th>\n",
       "      <td>4.576800</td>\n",
       "      <td>6.681592</td>\n",
       "      <td>8.323094</td>\n",
       "      <td>9.019000</td>\n",
       "      <td>0.451786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Simple Measure of Gobbledygook SMOG</th>\n",
       "      <td>10.110286</td>\n",
       "      <td>11.521299</td>\n",
       "      <td>12.760749</td>\n",
       "      <td>13.210278</td>\n",
       "      <td>0.471106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading Ease Level</th>\n",
       "      <td>92.465376</td>\n",
       "      <td>82.239781</td>\n",
       "      <td>75.110005</td>\n",
       "      <td>71.711107</td>\n",
       "      <td>-0.408414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Mean values                                 level1     level2     level3  \\\n",
       "The Gunning fog index GFI                45.132518  67.697721  91.866336   \n",
       "The Automated readability index ARI      14.238996  19.932585  25.719148   \n",
       "The Flesch reading ease FRE              90.625507  84.875840  82.799719   \n",
       "The Flesch-Kincaid grade level FKGL       4.576800   6.681592   8.323094   \n",
       "The Simple Measure of Gobbledygook SMOG  10.110286  11.521299  12.760749   \n",
       "Reading Ease Level                       92.465376  82.239781  75.110005   \n",
       "\n",
       "Mean values                                  level4  Pearson Score  \n",
       "The Gunning fog index GFI                105.669951       0.475915  \n",
       "The Automated readability index ARI       27.757700       0.472037  \n",
       "The Flesch reading ease FRE               81.032160      -0.402143  \n",
       "The Flesch-Kincaid grade level FKGL        9.019000       0.451786  \n",
       "The Simple Measure of Gobbledygook SMOG   13.210278       0.471106  \n",
       "Reading Ease Level                        71.711107      -0.408414  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, machine learning and deep learning applications can be used with the corpus' data to help develop NLP solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r.importmodel(camembert)\n",
    "#r.train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d8382c64f832ccbfeaab2a5edd229bc484a8f789774f43ccfafc2e4aa4ca7e5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
