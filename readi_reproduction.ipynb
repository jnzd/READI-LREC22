{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolashernandez/READI-LREC22/blob/main/readi_reproduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6OK4ukoLyFI"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook comes from the git repository available [here](https://github.com/nicolashernandez/READI-LREC22/)  \n",
        "It will show how to reproduce the contents of the READI paper available [here](https://cental.uclouvain.be/readi2022/accepted.html), then show a few examples on how to manipulate the library.  \n",
        "In order to speed up deep learning applications significantly, please enable GPU in this notebook's parameters :  \n",
        "Edit -> Notebook Settings -> Hardware Accelerator : GPU\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRRW2zl5LyFL"
      },
      "source": [
        "# Setup : Import dependencies then library"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup : NEED to restart runtime after downloading spacy model"
      ],
      "metadata": {
        "id": "2ZG-mjPydNdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!python -m spacy download fr_core_news_sm\n",
        "#This cell only needs to be run once."
      ],
      "metadata": {
        "id": "H2YEIjMZdcY0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart the runtime once (Ctrl+M . OR Runtime > Restart Runtime) then execute the following"
      ],
      "metadata": {
        "id": "QQLeuvYje2sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "tPqx634YdcsW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.util.set_data_path(spacy.load(\"fr_core_news_sm\")._path.parent.parent)\n",
        "#Quick hack to make sure the library's own spacy model works on colab by indicating where to locate models."
      ],
      "metadata": {
        "id": "Ur921r4pnWC-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup : Importing library and assorted data"
      ],
      "metadata": {
        "id": "xBexs2rPciL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# 1. Download project and set current directory\n",
        "!git clone https://github.com/nicolashernandez/READI-LREC22/\n",
        "%cd READI-LREC22/"
      ],
      "metadata": {
        "id": "jDdveq3ZUI__"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# 2. Install module, should take around a minute to install every dependency\n",
        "%cd readability\n",
        "!pip install .\n",
        "%cd .."
      ],
      "metadata": {
        "id": "Z_XksS_gUJOQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Add project directory to the path\n",
        "import sys,os\n",
        "sys.path.append(os.getcwd())\n",
        "sys.path.append(os.path.join(os.getcwd(),\"readability\"))"
      ],
      "metadata": {
        "id": "y_GOTUVpUJb8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1dlJDld-LyFO"
      },
      "outputs": [],
      "source": [
        "import readability"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recreating experiments"
      ],
      "metadata": {
        "id": "nTaUch-_Yd53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if fasttext and bert works from lib:\n",
        "from readability.models import models, fasttext, bert"
      ],
      "metadata": {
        "id": "rbQjwXU4ZuwM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reproducing the contents of table 2"
      ],
      "metadata": {
        "id": "EptHo7EPMqGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: do readability.Readability(corpus).compile().stats() and show results in latex format"
      ],
      "metadata": {
        "id": "Y1-GmxK2MpNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reproducting the contents of table 3"
      ],
      "metadata": {
        "id": "rYsSYkENM_Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: do readability.Readability(corpus).compile().scores() and show results in latex format"
      ],
      "metadata": {
        "id": "TJHbJyD5NBlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reproducing the contents of table 4 for MLP and SVM"
      ],
      "metadata": {
        "id": "qbko_k2ZNKH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: make relevant methods from decoupage_corpus.ipynb and/or linguisticAnalysis.ipynb \n",
        "#Then use these and show results in latex format"
      ],
      "metadata": {
        "id": "7qM-v7vhNJAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to reproduce the results in table 4 for fastText and CamemBERT"
      ],
      "metadata": {
        "id": "EJ3NnlP0yybH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following demonstration uses the csv files available in the data/ folder, encoded in one-hot vector format.  \n",
        "It relies on the ktrain library (wrapping around Keras) to help configure and train models for deep learning use."
      ],
      "metadata": {
        "id": "ZbrwZaRfLtjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###fastText"
      ],
      "metadata": {
        "id": "dsbPH6vmLpBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext.demo_doFastText() #Can pass \"ljl\", \"bibebook.com\", \"JeLisLibre\", or \"all\" as a parameter\n",
        "# Takes around 15 minutes without GPU for the ljl corpus (default parameter) on free colab\n",
        "# Takes around 3 minute with GPU enabled.\n",
        "\n",
        "# NOTE : the results may be a little different than what was shown in the paper.\n",
        "\n",
        "\n",
        "# Will test this after commit\n",
        "\n",
        "# FIXME : I noticed this isn't a \"true\" crossvalidation since the model is already trained in\n",
        "# consequent runs, this can be seen by the number of epochs being significantly lower, and\n",
        "# the starting accuracy being almost the same as in the last epoch of the previous run.\n",
        "\n",
        "# For future implementation in the library, this should be done :\n",
        "# We need to reset the model to its initial configuration/weights,\n",
        "# So something like this in the code should work :\n",
        "\n",
        "# BEFORE the \"for run in range(nb_runs)\":\n",
        "#\n",
        "#init_weights = []\n",
        "#for layer in learner.model.layers:\n",
        "#    init_weights.append(layer.get_weights()) # list of numpy arrays\n",
        "#\n",
        "#Then, within the loop :\n",
        "#for index in range(len(init_weights)):\n",
        "#    learner.model.layers[index].set_weight(init_weights[index])"
      ],
      "metadata": {
        "id": "F1Lqu_ZOv2ON",
        "outputId": "1260efc0-4e9c-4b73-faa8-99734a106219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "detected encoding: utf-8 (if wrong, set manually)\n",
            "['level1', 'level2', 'level3', 'level4']\n",
            "      level1  level2  level3  level4\n",
            "1100       0       0       1       0\n",
            "383        0       1       0       0\n",
            "632        0       1       0       0\n",
            "1189       0       0       1       0\n",
            "1471       0       0       1       0\n",
            "['level1', 'level2', 'level3', 'level4']\n",
            "      level1  level2  level3  level4\n",
            "1568       0       0       0       1\n",
            "158        1       0       0       0\n",
            "1121       0       0       1       0\n",
            "444        0       1       0       0\n",
            "277        0       1       0       0\n",
            "language: fr\n",
            "Word Counts: 19682\n",
            "Nrows: 1854\n",
            "1854 train sequences\n",
            "train sequence lengths:\n",
            "\tmean : 167\n",
            "\t95percentile : 369\n",
            "\t99percentile : 525\n",
            "x_train shape: (1854,150)\n",
            "y_train shape: (1854, 4)\n",
            "Is Multi-Label? False\n",
            "206 test sequences\n",
            "test sequence lengths:\n",
            "\tmean : 148\n",
            "\t95percentile : 304\n",
            "\t99percentile : 424\n",
            "x_test shape: (206,150)\n",
            "y_test shape: (206, 4)\n",
            "Is Multi-Label? False\n",
            "compiling word ID features...\n",
            "maxlen is 150\n",
            "done.\n",
            "-------------------------------------------------------run 0\n",
            "early_stopping automatically enabled at patience=5\n",
            "reduce_on_plateau automatically enabled at patience=2\n",
            "\n",
            "\n",
            "begin training using triangular learning rate policy with max lr of 0.0001...\n",
            "Epoch 1/1024\n",
            "58/58 [==============================] - 2s 11ms/step - loss: 1.7835 - accuracy: 0.2503 - val_loss: 1.3894 - val_accuracy: 0.2184\n",
            "Epoch 2/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.7220 - accuracy: 0.2923 - val_loss: 1.3859 - val_accuracy: 0.2184\n",
            "Epoch 3/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.7504 - accuracy: 0.2751 - val_loss: 1.3830 - val_accuracy: 0.2039\n",
            "Epoch 4/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.6918 - accuracy: 0.2934 - val_loss: 1.3798 - val_accuracy: 0.3252\n",
            "Epoch 5/1024\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.6623 - accuracy: 0.2875 - val_loss: 1.3780 - val_accuracy: 0.3350\n",
            "Epoch 6/1024\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.6706 - accuracy: 0.2794 - val_loss: 1.3762 - val_accuracy: 0.3398\n",
            "Epoch 7/1024\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.6834 - accuracy: 0.2729 - val_loss: 1.3739 - val_accuracy: 0.3301\n",
            "Epoch 8/1024\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.6478 - accuracy: 0.2902 - val_loss: 1.3707 - val_accuracy: 0.3641\n",
            "Epoch 9/1024\n",
            "58/58 [==============================] - 1s 15ms/step - loss: 1.6162 - accuracy: 0.3004 - val_loss: 1.3677 - val_accuracy: 0.3495\n",
            "Epoch 10/1024\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.5718 - accuracy: 0.3064 - val_loss: 1.3621 - val_accuracy: 0.3689\n",
            "Epoch 11/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5911 - accuracy: 0.3015 - val_loss: 1.3552 - val_accuracy: 0.3981\n",
            "Epoch 12/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5823 - accuracy: 0.2945 - val_loss: 1.3517 - val_accuracy: 0.4175\n",
            "Epoch 13/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5930 - accuracy: 0.2977 - val_loss: 1.3494 - val_accuracy: 0.4223\n",
            "Epoch 14/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5483 - accuracy: 0.3101 - val_loss: 1.3477 - val_accuracy: 0.4515\n",
            "Epoch 15/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.5596 - accuracy: 0.3166 - val_loss: 1.3455 - val_accuracy: 0.4320\n",
            "Epoch 16/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.5514 - accuracy: 0.3188 - val_loss: 1.3430 - val_accuracy: 0.4320\n",
            "Epoch 17/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.5411 - accuracy: 0.3285 - val_loss: 1.3389 - val_accuracy: 0.4320\n",
            "Epoch 18/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.5046 - accuracy: 0.3360 - val_loss: 1.3371 - val_accuracy: 0.4466\n",
            "Epoch 19/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4734 - accuracy: 0.3463 - val_loss: 1.3348 - val_accuracy: 0.4417\n",
            "Epoch 20/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4939 - accuracy: 0.3350 - val_loss: 1.3319 - val_accuracy: 0.4612\n",
            "Epoch 21/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4926 - accuracy: 0.3344 - val_loss: 1.3313 - val_accuracy: 0.4515\n",
            "Epoch 22/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4716 - accuracy: 0.3393 - val_loss: 1.3296 - val_accuracy: 0.4417\n",
            "Epoch 23/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4865 - accuracy: 0.3296 - val_loss: 1.3256 - val_accuracy: 0.4466\n",
            "Epoch 24/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4885 - accuracy: 0.3290 - val_loss: 1.3241 - val_accuracy: 0.4515\n",
            "Epoch 25/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4614 - accuracy: 0.3409 - val_loss: 1.3203 - val_accuracy: 0.4515\n",
            "Epoch 26/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4356 - accuracy: 0.3625 - val_loss: 1.3200 - val_accuracy: 0.4466\n",
            "Epoch 27/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4282 - accuracy: 0.3441 - val_loss: 1.3179 - val_accuracy: 0.4563\n",
            "Epoch 28/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4475 - accuracy: 0.3490 - val_loss: 1.3161 - val_accuracy: 0.4660\n",
            "Epoch 29/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3915 - accuracy: 0.3808 - val_loss: 1.3140 - val_accuracy: 0.4563\n",
            "Epoch 30/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4168 - accuracy: 0.3554 - val_loss: 1.3128 - val_accuracy: 0.4709\n",
            "Epoch 31/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4064 - accuracy: 0.3684 - val_loss: 1.3110 - val_accuracy: 0.4660\n",
            "Epoch 32/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4094 - accuracy: 0.3603 - val_loss: 1.3078 - val_accuracy: 0.4903\n",
            "Epoch 33/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3992 - accuracy: 0.3732 - val_loss: 1.3064 - val_accuracy: 0.4806\n",
            "Epoch 34/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3999 - accuracy: 0.3824 - val_loss: 1.3056 - val_accuracy: 0.4903\n",
            "Epoch 35/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3853 - accuracy: 0.3673 - val_loss: 1.3038 - val_accuracy: 0.4757\n",
            "Epoch 36/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3672 - accuracy: 0.3759 - val_loss: 1.3020 - val_accuracy: 0.4854\n",
            "Epoch 37/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3802 - accuracy: 0.3716 - val_loss: 1.3009 - val_accuracy: 0.5146\n",
            "Epoch 38/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3586 - accuracy: 0.3732 - val_loss: 1.2999 - val_accuracy: 0.5194\n",
            "Epoch 39/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3584 - accuracy: 0.3846 - val_loss: 1.2980 - val_accuracy: 0.5097\n",
            "Epoch 40/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3670 - accuracy: 0.3840 - val_loss: 1.2959 - val_accuracy: 0.5243\n",
            "Epoch 41/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3810 - accuracy: 0.3646 - val_loss: 1.2950 - val_accuracy: 0.5049\n",
            "Epoch 42/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3253 - accuracy: 0.4024 - val_loss: 1.2925 - val_accuracy: 0.5000\n",
            "Epoch 43/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3057 - accuracy: 0.4099 - val_loss: 1.2891 - val_accuracy: 0.5097\n",
            "Epoch 44/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3039 - accuracy: 0.4148 - val_loss: 1.2860 - val_accuracy: 0.5194\n",
            "Epoch 45/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2901 - accuracy: 0.4191 - val_loss: 1.2827 - val_accuracy: 0.5097\n",
            "Epoch 46/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2913 - accuracy: 0.4175 - val_loss: 1.2811 - val_accuracy: 0.5146\n",
            "Epoch 47/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2765 - accuracy: 0.4358 - val_loss: 1.2783 - val_accuracy: 0.5194\n",
            "Epoch 48/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3130 - accuracy: 0.4202 - val_loss: 1.2769 - val_accuracy: 0.5243\n",
            "Epoch 49/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2814 - accuracy: 0.4315 - val_loss: 1.2761 - val_accuracy: 0.5146\n",
            "Epoch 50/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2805 - accuracy: 0.4250 - val_loss: 1.2733 - val_accuracy: 0.5243\n",
            "Epoch 51/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2712 - accuracy: 0.4256 - val_loss: 1.2704 - val_accuracy: 0.5146\n",
            "Epoch 52/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2712 - accuracy: 0.4477 - val_loss: 1.2678 - val_accuracy: 0.5194\n",
            "Epoch 53/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2605 - accuracy: 0.4455 - val_loss: 1.2662 - val_accuracy: 0.5388\n",
            "Epoch 54/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2492 - accuracy: 0.4374 - val_loss: 1.2639 - val_accuracy: 0.5243\n",
            "Epoch 55/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2343 - accuracy: 0.4531 - val_loss: 1.2592 - val_accuracy: 0.5388\n",
            "Epoch 56/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2215 - accuracy: 0.4547 - val_loss: 1.2578 - val_accuracy: 0.5340\n",
            "Epoch 57/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2140 - accuracy: 0.4757 - val_loss: 1.2544 - val_accuracy: 0.5194\n",
            "Epoch 58/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2186 - accuracy: 0.4579 - val_loss: 1.2516 - val_accuracy: 0.5194\n",
            "Epoch 59/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2119 - accuracy: 0.4714 - val_loss: 1.2488 - val_accuracy: 0.5485\n",
            "Epoch 60/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1793 - accuracy: 0.4838 - val_loss: 1.2457 - val_accuracy: 0.5583\n",
            "Epoch 61/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1806 - accuracy: 0.4822 - val_loss: 1.2418 - val_accuracy: 0.5485\n",
            "Epoch 62/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1504 - accuracy: 0.5038 - val_loss: 1.2375 - val_accuracy: 0.5777\n",
            "Epoch 63/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1594 - accuracy: 0.4984 - val_loss: 1.2329 - val_accuracy: 0.5728\n",
            "Epoch 64/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1250 - accuracy: 0.5313 - val_loss: 1.2311 - val_accuracy: 0.5825\n",
            "Epoch 65/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1323 - accuracy: 0.5151 - val_loss: 1.2273 - val_accuracy: 0.5825\n",
            "Epoch 66/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1247 - accuracy: 0.5162 - val_loss: 1.2241 - val_accuracy: 0.5777\n",
            "Epoch 67/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1061 - accuracy: 0.5221 - val_loss: 1.2204 - val_accuracy: 0.5874\n",
            "Epoch 68/1024\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.1092 - accuracy: 0.5097 - val_loss: 1.2174 - val_accuracy: 0.5874\n",
            "Epoch 69/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1621 - accuracy: 0.4811 - val_loss: 1.2143 - val_accuracy: 0.5874\n",
            "Epoch 70/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1138 - accuracy: 0.5367 - val_loss: 1.2121 - val_accuracy: 0.5825\n",
            "Epoch 71/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1111 - accuracy: 0.5291 - val_loss: 1.2081 - val_accuracy: 0.5825\n",
            "Epoch 72/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0925 - accuracy: 0.5302 - val_loss: 1.2057 - val_accuracy: 0.5777\n",
            "Epoch 73/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0705 - accuracy: 0.5410 - val_loss: 1.2017 - val_accuracy: 0.5825\n",
            "Epoch 74/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0642 - accuracy: 0.5378 - val_loss: 1.1977 - val_accuracy: 0.5728\n",
            "Epoch 75/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0760 - accuracy: 0.5405 - val_loss: 1.1944 - val_accuracy: 0.5728\n",
            "Epoch 76/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0714 - accuracy: 0.5448 - val_loss: 1.1888 - val_accuracy: 0.5777\n",
            "Epoch 77/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0726 - accuracy: 0.5469 - val_loss: 1.1865 - val_accuracy: 0.5728\n",
            "Epoch 78/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0546 - accuracy: 0.5577 - val_loss: 1.1835 - val_accuracy: 0.5728\n",
            "Epoch 79/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0487 - accuracy: 0.5626 - val_loss: 1.1808 - val_accuracy: 0.5777\n",
            "Epoch 80/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0162 - accuracy: 0.5696 - val_loss: 1.1761 - val_accuracy: 0.5728\n",
            "Epoch 81/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0319 - accuracy: 0.5636 - val_loss: 1.1731 - val_accuracy: 0.5583\n",
            "Epoch 82/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9983 - accuracy: 0.5744 - val_loss: 1.1671 - val_accuracy: 0.5680\n",
            "Epoch 83/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9657 - accuracy: 0.6068 - val_loss: 1.1622 - val_accuracy: 0.5680\n",
            "Epoch 84/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9995 - accuracy: 0.5841 - val_loss: 1.1559 - val_accuracy: 0.5728\n",
            "Epoch 85/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9674 - accuracy: 0.6063 - val_loss: 1.1522 - val_accuracy: 0.5631\n",
            "Epoch 86/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9570 - accuracy: 0.5885 - val_loss: 1.1478 - val_accuracy: 0.5680\n",
            "Epoch 87/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9482 - accuracy: 0.6057 - val_loss: 1.1436 - val_accuracy: 0.5631\n",
            "Epoch 88/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9635 - accuracy: 0.6014 - val_loss: 1.1384 - val_accuracy: 0.5680\n",
            "Epoch 89/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9508 - accuracy: 0.6154 - val_loss: 1.1360 - val_accuracy: 0.5680\n",
            "Epoch 90/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9438 - accuracy: 0.6246 - val_loss: 1.1331 - val_accuracy: 0.5631\n",
            "Epoch 91/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9471 - accuracy: 0.6003 - val_loss: 1.1302 - val_accuracy: 0.5728\n",
            "Epoch 92/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8989 - accuracy: 0.6343 - val_loss: 1.1257 - val_accuracy: 0.5631\n",
            "Epoch 93/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9110 - accuracy: 0.6332 - val_loss: 1.1207 - val_accuracy: 0.5728\n",
            "Epoch 94/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8920 - accuracy: 0.6435 - val_loss: 1.1175 - val_accuracy: 0.5777\n",
            "Epoch 95/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9002 - accuracy: 0.6375 - val_loss: 1.1124 - val_accuracy: 0.5777\n",
            "Epoch 96/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8722 - accuracy: 0.6505 - val_loss: 1.1067 - val_accuracy: 0.5680\n",
            "Epoch 97/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8486 - accuracy: 0.6650 - val_loss: 1.1042 - val_accuracy: 0.5728\n",
            "Epoch 98/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8590 - accuracy: 0.6607 - val_loss: 1.0986 - val_accuracy: 0.5777\n",
            "Epoch 99/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8516 - accuracy: 0.6694 - val_loss: 1.0945 - val_accuracy: 0.5777\n",
            "Epoch 100/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8094 - accuracy: 0.6839 - val_loss: 1.0895 - val_accuracy: 0.5728\n",
            "Epoch 101/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8328 - accuracy: 0.6672 - val_loss: 1.0861 - val_accuracy: 0.5728\n",
            "Epoch 102/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8311 - accuracy: 0.6796 - val_loss: 1.0815 - val_accuracy: 0.5874\n",
            "Epoch 103/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8191 - accuracy: 0.6726 - val_loss: 1.0756 - val_accuracy: 0.5874\n",
            "Epoch 104/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8043 - accuracy: 0.6899 - val_loss: 1.0703 - val_accuracy: 0.5825\n",
            "Epoch 105/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7809 - accuracy: 0.6947 - val_loss: 1.0660 - val_accuracy: 0.6019\n",
            "Epoch 106/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7677 - accuracy: 0.7033 - val_loss: 1.0631 - val_accuracy: 0.5971\n",
            "Epoch 107/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7849 - accuracy: 0.6866 - val_loss: 1.0587 - val_accuracy: 0.5922\n",
            "Epoch 108/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7688 - accuracy: 0.7055 - val_loss: 1.0566 - val_accuracy: 0.5874\n",
            "Epoch 109/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7588 - accuracy: 0.7152 - val_loss: 1.0524 - val_accuracy: 0.5971\n",
            "Epoch 110/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7839 - accuracy: 0.6888 - val_loss: 1.0461 - val_accuracy: 0.6019\n",
            "Epoch 111/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7454 - accuracy: 0.7228 - val_loss: 1.0412 - val_accuracy: 0.6068\n",
            "Epoch 112/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7255 - accuracy: 0.7346 - val_loss: 1.0358 - val_accuracy: 0.6019\n",
            "Epoch 113/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6975 - accuracy: 0.7341 - val_loss: 1.0311 - val_accuracy: 0.5971\n",
            "Epoch 114/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7009 - accuracy: 0.7249 - val_loss: 1.0274 - val_accuracy: 0.6019\n",
            "Epoch 115/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7305 - accuracy: 0.7125 - val_loss: 1.0230 - val_accuracy: 0.6117\n",
            "Epoch 116/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7190 - accuracy: 0.7330 - val_loss: 1.0200 - val_accuracy: 0.6165\n",
            "Epoch 117/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6812 - accuracy: 0.7422 - val_loss: 1.0159 - val_accuracy: 0.6165\n",
            "Epoch 118/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6897 - accuracy: 0.7373 - val_loss: 1.0116 - val_accuracy: 0.6068\n",
            "Epoch 119/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6714 - accuracy: 0.7481 - val_loss: 1.0050 - val_accuracy: 0.6165\n",
            "Epoch 120/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6410 - accuracy: 0.7670 - val_loss: 1.0013 - val_accuracy: 0.6117\n",
            "Epoch 121/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6552 - accuracy: 0.7573 - val_loss: 0.9979 - val_accuracy: 0.6068\n",
            "Epoch 122/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6485 - accuracy: 0.7562 - val_loss: 0.9949 - val_accuracy: 0.6117\n",
            "Epoch 123/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6485 - accuracy: 0.7449 - val_loss: 0.9919 - val_accuracy: 0.6117\n",
            "Epoch 124/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6336 - accuracy: 0.7697 - val_loss: 0.9861 - val_accuracy: 0.6165\n",
            "Epoch 125/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6058 - accuracy: 0.7826 - val_loss: 0.9815 - val_accuracy: 0.6165\n",
            "Epoch 126/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6335 - accuracy: 0.7643 - val_loss: 0.9790 - val_accuracy: 0.6165\n",
            "Epoch 127/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5886 - accuracy: 0.7837 - val_loss: 0.9750 - val_accuracy: 0.6214\n",
            "Epoch 128/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5783 - accuracy: 0.7934 - val_loss: 0.9713 - val_accuracy: 0.6214\n",
            "Epoch 129/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5967 - accuracy: 0.7799 - val_loss: 0.9670 - val_accuracy: 0.6214\n",
            "Epoch 130/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5883 - accuracy: 0.7810 - val_loss: 0.9643 - val_accuracy: 0.6165\n",
            "Epoch 131/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5663 - accuracy: 0.7945 - val_loss: 0.9612 - val_accuracy: 0.6068\n",
            "Epoch 132/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5623 - accuracy: 0.7934 - val_loss: 0.9597 - val_accuracy: 0.6165\n",
            "Epoch 133/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5480 - accuracy: 0.7961 - val_loss: 0.9566 - val_accuracy: 0.6117\n",
            "Epoch 134/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5397 - accuracy: 0.8091 - val_loss: 0.9533 - val_accuracy: 0.6068\n",
            "Epoch 135/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5250 - accuracy: 0.8118 - val_loss: 0.9502 - val_accuracy: 0.6068\n",
            "Epoch 136/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5280 - accuracy: 0.8096 - val_loss: 0.9462 - val_accuracy: 0.6165\n",
            "Epoch 137/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5052 - accuracy: 0.8128 - val_loss: 0.9433 - val_accuracy: 0.6214\n",
            "Epoch 138/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5144 - accuracy: 0.8161 - val_loss: 0.9395 - val_accuracy: 0.6262\n",
            "Epoch 139/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5420 - accuracy: 0.8037 - val_loss: 0.9362 - val_accuracy: 0.6165\n",
            "Epoch 140/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5195 - accuracy: 0.8080 - val_loss: 0.9330 - val_accuracy: 0.6165\n",
            "Epoch 141/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4919 - accuracy: 0.8198 - val_loss: 0.9288 - val_accuracy: 0.6214\n",
            "Epoch 142/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5084 - accuracy: 0.8172 - val_loss: 0.9278 - val_accuracy: 0.6214\n",
            "Epoch 143/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4536 - accuracy: 0.8409 - val_loss: 0.9273 - val_accuracy: 0.6214\n",
            "Epoch 144/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5082 - accuracy: 0.8112 - val_loss: 0.9216 - val_accuracy: 0.6262\n",
            "Epoch 145/1024\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.4890 - accuracy: 0.8301 - val_loss: 0.9192 - val_accuracy: 0.6214\n",
            "Epoch 146/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4767 - accuracy: 0.8355 - val_loss: 0.9162 - val_accuracy: 0.6214\n",
            "Epoch 147/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4603 - accuracy: 0.8290 - val_loss: 0.9137 - val_accuracy: 0.6262\n",
            "Epoch 148/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4517 - accuracy: 0.8490 - val_loss: 0.9103 - val_accuracy: 0.6311\n",
            "Epoch 149/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4503 - accuracy: 0.8474 - val_loss: 0.9069 - val_accuracy: 0.6311\n",
            "Epoch 150/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4363 - accuracy: 0.8447 - val_loss: 0.9034 - val_accuracy: 0.6214\n",
            "Epoch 151/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4502 - accuracy: 0.8414 - val_loss: 0.9005 - val_accuracy: 0.6214\n",
            "Epoch 152/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4130 - accuracy: 0.8635 - val_loss: 0.8997 - val_accuracy: 0.6214\n",
            "Epoch 153/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4454 - accuracy: 0.8409 - val_loss: 0.8962 - val_accuracy: 0.6214\n",
            "Epoch 154/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4001 - accuracy: 0.8641 - val_loss: 0.8957 - val_accuracy: 0.6214\n",
            "Epoch 155/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4102 - accuracy: 0.8501 - val_loss: 0.8936 - val_accuracy: 0.6262\n",
            "Epoch 156/1024\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.8501 - val_loss: 0.8892 - val_accuracy: 0.6262\n",
            "Epoch 157/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3996 - accuracy: 0.8625 - val_loss: 0.8874 - val_accuracy: 0.6262\n",
            "Epoch 158/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.8479 - val_loss: 0.8840 - val_accuracy: 0.6262\n",
            "Epoch 159/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3760 - accuracy: 0.8738 - val_loss: 0.8803 - val_accuracy: 0.6262\n",
            "Epoch 160/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4030 - accuracy: 0.8635 - val_loss: 0.8780 - val_accuracy: 0.6311\n",
            "Epoch 161/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3781 - accuracy: 0.8652 - val_loss: 0.8749 - val_accuracy: 0.6311\n",
            "Epoch 162/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4045 - accuracy: 0.8560 - val_loss: 0.8743 - val_accuracy: 0.6359\n",
            "Epoch 163/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4034 - accuracy: 0.8528 - val_loss: 0.8741 - val_accuracy: 0.6262\n",
            "Epoch 164/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3545 - accuracy: 0.8754 - val_loss: 0.8710 - val_accuracy: 0.6262\n",
            "Epoch 165/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3616 - accuracy: 0.8716 - val_loss: 0.8692 - val_accuracy: 0.6359\n",
            "Epoch 166/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3649 - accuracy: 0.8684 - val_loss: 0.8658 - val_accuracy: 0.6408\n",
            "Epoch 167/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3719 - accuracy: 0.8743 - val_loss: 0.8654 - val_accuracy: 0.6408\n",
            "Epoch 168/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3423 - accuracy: 0.8792 - val_loss: 0.8634 - val_accuracy: 0.6359\n",
            "Epoch 169/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3498 - accuracy: 0.8792 - val_loss: 0.8595 - val_accuracy: 0.6456\n",
            "Epoch 170/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3405 - accuracy: 0.8883 - val_loss: 0.8591 - val_accuracy: 0.6456\n",
            "Epoch 171/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3443 - accuracy: 0.8786 - val_loss: 0.8583 - val_accuracy: 0.6456\n",
            "Epoch 172/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3571 - accuracy: 0.8754 - val_loss: 0.8567 - val_accuracy: 0.6408\n",
            "Epoch 173/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3076 - accuracy: 0.8905 - val_loss: 0.8536 - val_accuracy: 0.6408\n",
            "Epoch 174/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3259 - accuracy: 0.8857 - val_loss: 0.8529 - val_accuracy: 0.6456\n",
            "Epoch 175/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3075 - accuracy: 0.8954 - val_loss: 0.8516 - val_accuracy: 0.6505\n",
            "Epoch 176/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3070 - accuracy: 0.8991 - val_loss: 0.8485 - val_accuracy: 0.6553\n",
            "Epoch 177/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3210 - accuracy: 0.8883 - val_loss: 0.8475 - val_accuracy: 0.6456\n",
            "Epoch 178/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2914 - accuracy: 0.9024 - val_loss: 0.8445 - val_accuracy: 0.6505\n",
            "Epoch 179/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3320 - accuracy: 0.8808 - val_loss: 0.8414 - val_accuracy: 0.6456\n",
            "Epoch 180/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3073 - accuracy: 0.8883 - val_loss: 0.8418 - val_accuracy: 0.6505\n",
            "Epoch 181/1024\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3095 - accuracy: 0.8909\n",
            "Epoch 00181: Reducing Max LR on Plateau: new max lr will be 5e-05 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3096 - accuracy: 0.8916 - val_loss: 0.8419 - val_accuracy: 0.6408\n",
            "Epoch 182/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2972 - accuracy: 0.9051 - val_loss: 0.8400 - val_accuracy: 0.6408\n",
            "Epoch 183/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.2896 - accuracy: 0.9002 - val_loss: 0.8407 - val_accuracy: 0.6505\n",
            "Epoch 184/1024\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.3055 - accuracy: 0.8980\n",
            "Epoch 00184: Reducing Max LR on Plateau: new max lr will be 2.5e-05 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3057 - accuracy: 0.8975 - val_loss: 0.8412 - val_accuracy: 0.6311\n",
            "Epoch 185/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2750 - accuracy: 0.9121 - val_loss: 0.8394 - val_accuracy: 0.6456\n",
            "Epoch 186/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.2742 - accuracy: 0.9029 - val_loss: 0.8396 - val_accuracy: 0.6505\n",
            "Epoch 187/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2938 - accuracy: 0.8964 - val_loss: 0.8381 - val_accuracy: 0.6505\n",
            "Epoch 188/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3013 - accuracy: 0.9013 - val_loss: 0.8362 - val_accuracy: 0.6553\n",
            "Epoch 189/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3136 - accuracy: 0.8878 - val_loss: 0.8367 - val_accuracy: 0.6456\n",
            "Epoch 190/1024\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.2798 - accuracy: 0.9062\n",
            "Epoch 00190: Reducing Max LR on Plateau: new max lr will be 1.25e-05 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.2827 - accuracy: 0.9051 - val_loss: 0.8365 - val_accuracy: 0.6553\n",
            "Epoch 191/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2942 - accuracy: 0.9029 - val_loss: 0.8353 - val_accuracy: 0.6553\n",
            "Epoch 192/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2808 - accuracy: 0.9078 - val_loss: 0.8354 - val_accuracy: 0.6553\n",
            "Epoch 193/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2851 - accuracy: 0.9148 - val_loss: 0.8351 - val_accuracy: 0.6602\n",
            "Epoch 194/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2858 - accuracy: 0.9061 - val_loss: 0.8355 - val_accuracy: 0.6505\n",
            "Epoch 195/1024\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.2965 - accuracy: 0.8928\n",
            "Epoch 00195: Reducing Max LR on Plateau: new max lr will be 6.25e-06 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2909 - accuracy: 0.8991 - val_loss: 0.8362 - val_accuracy: 0.6456\n",
            "Epoch 196/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.2806 - accuracy: 0.9078 - val_loss: 0.8360 - val_accuracy: 0.6505\n",
            "Epoch 197/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2806 - accuracy: 0.9040 - val_loss: 0.8339 - val_accuracy: 0.6602\n",
            "Epoch 198/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2584 - accuracy: 0.9191 - val_loss: 0.8332 - val_accuracy: 0.6602\n",
            "Epoch 199/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2794 - accuracy: 0.9040 - val_loss: 0.8321 - val_accuracy: 0.6408\n",
            "Epoch 200/1024\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.2825 - accuracy: 0.9018 - val_loss: 0.8333 - val_accuracy: 0.6505\n",
            "Epoch 201/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2837 - accuracy: 0.9040 - val_loss: 0.8319 - val_accuracy: 0.6602\n",
            "Epoch 202/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.2929 - accuracy: 0.9040 - val_loss: 0.8337 - val_accuracy: 0.6456\n",
            "Epoch 203/1024\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.2358 - accuracy: 0.9284\n",
            "Epoch 00203: Reducing Max LR on Plateau: new max lr will be 3.125e-06 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.2371 - accuracy: 0.9277 - val_loss: 0.8352 - val_accuracy: 0.6359\n",
            "Epoch 204/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2858 - accuracy: 0.9029 - val_loss: 0.8337 - val_accuracy: 0.6456\n",
            "Epoch 205/1024\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.2573 - accuracy: 0.9079\n",
            "Epoch 00205: Reducing Max LR on Plateau: new max lr will be 1.5625e-06 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2567 - accuracy: 0.9083 - val_loss: 0.8345 - val_accuracy: 0.6359\n",
            "Epoch 206/1024\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.2727 - accuracy: 0.9123Restoring model weights from the end of the best epoch: 201.\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2737 - accuracy: 0.9132 - val_loss: 0.8345 - val_accuracy: 0.6408\n",
            "Epoch 206: early stopping\n",
            "Weights from best epoch have been loaded into model.\n",
            "run 0 CORPUSNAME ljl class_names ['level1', 'level2', 'level3', 'level4']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      level1       0.43      0.42      0.43        24\n",
            "      level2       0.71      0.69      0.70        70\n",
            "      level3       0.66      0.70      0.68        67\n",
            "      level4       0.70      0.69      0.70        45\n",
            "\n",
            "    accuracy                           0.66       206\n",
            "   macro avg       0.63      0.62      0.62       206\n",
            "weighted avg       0.66      0.66      0.66       206\n",
            "\n",
            "-------------------------------------------------------run 1\n",
            "early_stopping automatically enabled at patience=5\n",
            "reduce_on_plateau automatically enabled at patience=2\n",
            "\n",
            "\n",
            "begin training using triangular learning rate policy with max lr of 0.0001...\n",
            "Epoch 1/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2654 - accuracy: 0.9164 - val_loss: 0.8308 - val_accuracy: 0.6602\n",
            "Epoch 2/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2652 - accuracy: 0.9099 - val_loss: 0.8299 - val_accuracy: 0.6602\n",
            "Epoch 3/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2662 - accuracy: 0.9137 - val_loss: 0.8306 - val_accuracy: 0.6602\n",
            "Epoch 4/1024\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.2826 - accuracy: 0.9008\n",
            "Epoch 00004: Reducing Max LR on Plateau: new max lr will be 5e-05 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2833 - accuracy: 0.9013 - val_loss: 0.8310 - val_accuracy: 0.6505\n",
            "Epoch 5/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2502 - accuracy: 0.9137 - val_loss: 0.8323 - val_accuracy: 0.6553\n",
            "Epoch 6/1024\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.2658 - accuracy: 0.9145\n",
            "Epoch 00006: Reducing Max LR on Plateau: new max lr will be 2.5e-05 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.2678 - accuracy: 0.9137 - val_loss: 0.8312 - val_accuracy: 0.6505\n",
            "Epoch 7/1024\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.2562 - accuracy: 0.9177Restoring model weights from the end of the best epoch: 2.\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2562 - accuracy: 0.9186 - val_loss: 0.8313 - val_accuracy: 0.6553\n",
            "Epoch 7: early stopping\n",
            "Weights from best epoch have been loaded into model.\n",
            "run 1 CORPUSNAME ljl class_names ['level1', 'level2', 'level3', 'level4']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      level1       0.43      0.42      0.43        24\n",
            "      level2       0.71      0.69      0.70        70\n",
            "      level3       0.66      0.70      0.68        67\n",
            "      level4       0.70      0.69      0.70        45\n",
            "\n",
            "    accuracy                           0.66       206\n",
            "   macro avg       0.63      0.62      0.62       206\n",
            "weighted avg       0.66      0.66      0.66       206\n",
            "\n",
            "-------------------------------------------------------run 2\n",
            "early_stopping automatically enabled at patience=5\n",
            "reduce_on_plateau automatically enabled at patience=2\n",
            "\n",
            "\n",
            "begin training using triangular learning rate policy with max lr of 0.0001...\n",
            "Epoch 1/1024\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.2817 - accuracy: 0.9013 - val_loss: 0.8324 - val_accuracy: 0.6553\n",
            "Epoch 2/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2538 - accuracy: 0.9142 - val_loss: 0.8281 - val_accuracy: 0.6456\n",
            "Epoch 3/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.2772 - accuracy: 0.9051 - val_loss: 0.8275 - val_accuracy: 0.6650\n",
            "Epoch 4/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2612 - accuracy: 0.9110 - val_loss: 0.8248 - val_accuracy: 0.6553\n",
            "Epoch 5/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2490 - accuracy: 0.9234 - val_loss: 0.8248 - val_accuracy: 0.6456\n",
            "Epoch 6/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2560 - accuracy: 0.9061 - val_loss: 0.8236 - val_accuracy: 0.6505\n",
            "Epoch 7/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.2694 - accuracy: 0.9061 - val_loss: 0.8231 - val_accuracy: 0.6456\n",
            "Epoch 8/1024\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.2364 - accuracy: 0.9272 - val_loss: 0.8220 - val_accuracy: 0.6408\n",
            "Epoch 9/1024\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.2450 - accuracy: 0.9126 - val_loss: 0.8222 - val_accuracy: 0.6456\n",
            "Epoch 10/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2629 - accuracy: 0.9115 - val_loss: 0.8212 - val_accuracy: 0.6456\n",
            "Epoch 11/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2373 - accuracy: 0.9229 - val_loss: 0.8186 - val_accuracy: 0.6408\n",
            "Epoch 12/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2470 - accuracy: 0.9142 - val_loss: 0.8176 - val_accuracy: 0.6456\n",
            "Epoch 13/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2348 - accuracy: 0.9196 - val_loss: 0.8173 - val_accuracy: 0.6456\n",
            "Epoch 14/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2544 - accuracy: 0.9088 - val_loss: 0.8166 - val_accuracy: 0.6408\n",
            "Epoch 15/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2453 - accuracy: 0.9202 - val_loss: 0.8169 - val_accuracy: 0.6505\n",
            "Epoch 16/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2418 - accuracy: 0.9159 - val_loss: 0.8164 - val_accuracy: 0.6408\n",
            "Epoch 17/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2186 - accuracy: 0.9315 - val_loss: 0.8155 - val_accuracy: 0.6359\n",
            "Epoch 18/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2323 - accuracy: 0.9202 - val_loss: 0.8152 - val_accuracy: 0.6505\n",
            "Epoch 19/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2339 - accuracy: 0.9272 - val_loss: 0.8128 - val_accuracy: 0.6505\n",
            "Epoch 20/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1997 - accuracy: 0.9369 - val_loss: 0.8128 - val_accuracy: 0.6505\n",
            "Epoch 21/1024\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.2126 - accuracy: 0.9293 - val_loss: 0.8128 - val_accuracy: 0.6456\n",
            "Epoch 22/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2133 - accuracy: 0.9304 - val_loss: 0.8129 - val_accuracy: 0.6505\n",
            "Epoch 23/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2100 - accuracy: 0.9331 - val_loss: 0.8123 - val_accuracy: 0.6408\n",
            "Epoch 24/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2271 - accuracy: 0.9277 - val_loss: 0.8122 - val_accuracy: 0.6456\n",
            "Epoch 25/1024\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.2012 - accuracy: 0.9380 - val_loss: 0.8113 - val_accuracy: 0.6505\n",
            "Epoch 26/1024\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.2039 - accuracy: 0.9315 - val_loss: 0.8122 - val_accuracy: 0.6456\n",
            "Epoch 27/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1844 - accuracy: 0.9417 - val_loss: 0.8108 - val_accuracy: 0.6505\n",
            "Epoch 28/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1778 - accuracy: 0.9380 - val_loss: 0.8114 - val_accuracy: 0.6505\n",
            "Epoch 29/1024\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.2028 - accuracy: 0.9259\n",
            "Epoch 00029: Reducing Max LR on Plateau: new max lr will be 5e-05 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2002 - accuracy: 0.9277 - val_loss: 0.8113 - val_accuracy: 0.6650\n",
            "Epoch 30/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1923 - accuracy: 0.9401 - val_loss: 0.8112 - val_accuracy: 0.6650\n",
            "Epoch 31/1024\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.1848 - accuracy: 0.9434\n",
            "Epoch 00031: Reducing Max LR on Plateau: new max lr will be 2.5e-05 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1832 - accuracy: 0.9417 - val_loss: 0.8111 - val_accuracy: 0.6553\n",
            "Epoch 32/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1828 - accuracy: 0.9374 - val_loss: 0.8099 - val_accuracy: 0.6650\n",
            "Epoch 33/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2064 - accuracy: 0.9283 - val_loss: 0.8091 - val_accuracy: 0.6650\n",
            "Epoch 34/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2113 - accuracy: 0.9223 - val_loss: 0.8082 - val_accuracy: 0.6650\n",
            "Epoch 35/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1959 - accuracy: 0.9347 - val_loss: 0.8095 - val_accuracy: 0.6650\n",
            "Epoch 36/1024\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.1996 - accuracy: 0.9316\n",
            "Epoch 00036: Reducing Max LR on Plateau: new max lr will be 1.25e-05 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2043 - accuracy: 0.9288 - val_loss: 0.8112 - val_accuracy: 0.6553\n",
            "Epoch 37/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1722 - accuracy: 0.9401 - val_loss: 0.8097 - val_accuracy: 0.6602\n",
            "Epoch 38/1024\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.2056 - accuracy: 0.9275\n",
            "Epoch 00038: Reducing Max LR on Plateau: new max lr will be 6.25e-06 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2040 - accuracy: 0.9283 - val_loss: 0.8086 - val_accuracy: 0.6650\n",
            "Epoch 39/1024\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.2090 - accuracy: 0.9298Restoring model weights from the end of the best epoch: 34.\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2085 - accuracy: 0.9299 - val_loss: 0.8083 - val_accuracy: 0.6650\n",
            "Epoch 39: early stopping\n",
            "Weights from best epoch have been loaded into model.\n",
            "run 2 CORPUSNAME ljl class_names ['level1', 'level2', 'level3', 'level4']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      level1       0.45      0.38      0.41        24\n",
            "      level2       0.71      0.69      0.70        70\n",
            "      level3       0.66      0.72      0.69        67\n",
            "      level4       0.71      0.71      0.71        45\n",
            "\n",
            "    accuracy                           0.67       206\n",
            "   macro avg       0.63      0.62      0.63       206\n",
            "weighted avg       0.66      0.67      0.66       206\n",
            "\n",
            "-------------------------------------------------------run 3\n",
            "early_stopping automatically enabled at patience=5\n",
            "reduce_on_plateau automatically enabled at patience=2\n",
            "\n",
            "\n",
            "begin training using triangular learning rate policy with max lr of 0.0001...\n",
            "Epoch 1/1024\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1999 - accuracy: 0.9331 - val_loss: 0.8069 - val_accuracy: 0.6699\n",
            "Epoch 2/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1793 - accuracy: 0.9466 - val_loss: 0.8091 - val_accuracy: 0.6650\n",
            "Epoch 3/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2009 - accuracy: 0.9315 - val_loss: 0.8067 - val_accuracy: 0.6553\n",
            "Epoch 4/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1917 - accuracy: 0.9353 - val_loss: 0.8072 - val_accuracy: 0.6602\n",
            "Epoch 5/1024\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9474\n",
            "Epoch 00005: Reducing Max LR on Plateau: new max lr will be 5e-05 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1756 - accuracy: 0.9482 - val_loss: 0.8070 - val_accuracy: 0.6602\n",
            "Epoch 6/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1710 - accuracy: 0.9401 - val_loss: 0.8074 - val_accuracy: 0.6650\n",
            "Epoch 7/1024\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.1967 - accuracy: 0.9350\n",
            "Epoch 00007: Reducing Max LR on Plateau: new max lr will be 2.5e-05 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1992 - accuracy: 0.9358 - val_loss: 0.8074 - val_accuracy: 0.6650\n",
            "Epoch 8/1024\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.1711 - accuracy: 0.9375Restoring model weights from the end of the best epoch: 3.\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1706 - accuracy: 0.9391 - val_loss: 0.8074 - val_accuracy: 0.6650\n",
            "Epoch 8: early stopping\n",
            "Weights from best epoch have been loaded into model.\n",
            "run 3 CORPUSNAME ljl class_names ['level1', 'level2', 'level3', 'level4']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      level1       0.46      0.46      0.46        24\n",
            "      level2       0.69      0.69      0.69        70\n",
            "      level3       0.66      0.66      0.66        67\n",
            "      level4       0.71      0.71      0.71        45\n",
            "\n",
            "    accuracy                           0.66       206\n",
            "   macro avg       0.63      0.63      0.63       206\n",
            "weighted avg       0.66      0.66      0.66       206\n",
            "\n",
            "-------------------------------------------------------run 4\n",
            "early_stopping automatically enabled at patience=5\n",
            "reduce_on_plateau automatically enabled at patience=2\n",
            "\n",
            "\n",
            "begin training using triangular learning rate policy with max lr of 0.0001...\n",
            "Epoch 1/1024\n",
            "58/58 [==============================] - 2s 9ms/step - loss: 0.1863 - accuracy: 0.9315 - val_loss: 0.8050 - val_accuracy: 0.6699\n",
            "Epoch 2/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2091 - accuracy: 0.9288 - val_loss: 0.8057 - val_accuracy: 0.6650\n",
            "Epoch 3/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1890 - accuracy: 0.9326 - val_loss: 0.8047 - val_accuracy: 0.6699\n",
            "Epoch 4/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1759 - accuracy: 0.9407 - val_loss: 0.8047 - val_accuracy: 0.6796\n",
            "Epoch 5/1024\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1979 - accuracy: 0.9396 - val_loss: 0.8042 - val_accuracy: 0.6796\n",
            "Epoch 6/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1507 - accuracy: 0.9493 - val_loss: 0.8041 - val_accuracy: 0.6699\n",
            "Epoch 7/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1638 - accuracy: 0.9498 - val_loss: 0.8049 - val_accuracy: 0.6845\n",
            "Epoch 8/1024\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.1759 - accuracy: 0.9369\n",
            "Epoch 00008: Reducing Max LR on Plateau: new max lr will be 5e-05 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.1734 - accuracy: 0.9374 - val_loss: 0.8041 - val_accuracy: 0.6796\n",
            "Epoch 9/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1984 - accuracy: 0.9337 - val_loss: 0.8027 - val_accuracy: 0.6796\n",
            "Epoch 10/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1762 - accuracy: 0.9434 - val_loss: 0.8037 - val_accuracy: 0.6699\n",
            "Epoch 11/1024\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.1601 - accuracy: 0.9471\n",
            "Epoch 00011: Reducing Max LR on Plateau: new max lr will be 2.5e-05 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1622 - accuracy: 0.9482 - val_loss: 0.8028 - val_accuracy: 0.6748\n",
            "Epoch 12/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1590 - accuracy: 0.9461 - val_loss: 0.8015 - val_accuracy: 0.6796\n",
            "Epoch 13/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1519 - accuracy: 0.9509 - val_loss: 0.8023 - val_accuracy: 0.6748\n",
            "Epoch 14/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1761 - accuracy: 0.9396 - val_loss: 0.8014 - val_accuracy: 0.6796\n",
            "Epoch 15/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1709 - accuracy: 0.9450 - val_loss: 0.8015 - val_accuracy: 0.6796\n",
            "Epoch 16/1024\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.1666 - accuracy: 0.9442\n",
            "Epoch 00016: Reducing Max LR on Plateau: new max lr will be 1.25e-05 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1629 - accuracy: 0.9471 - val_loss: 0.8024 - val_accuracy: 0.6748\n",
            "Epoch 17/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1604 - accuracy: 0.9455 - val_loss: 0.8031 - val_accuracy: 0.6650\n",
            "Epoch 18/1024\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9501\n",
            "Epoch 00018: Reducing Max LR on Plateau: new max lr will be 6.25e-06 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1554 - accuracy: 0.9504 - val_loss: 0.8026 - val_accuracy: 0.6748\n",
            "Epoch 19/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1732 - accuracy: 0.9471 - val_loss: 0.8008 - val_accuracy: 0.6796\n",
            "Epoch 20/1024\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.1690 - accuracy: 0.9428 - val_loss: 0.8004 - val_accuracy: 0.6748\n",
            "Epoch 21/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1719 - accuracy: 0.9396 - val_loss: 0.8018 - val_accuracy: 0.6748\n",
            "Epoch 22/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1461 - accuracy: 0.9558 - val_loss: 0.7998 - val_accuracy: 0.6845\n",
            "Epoch 23/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1710 - accuracy: 0.9428 - val_loss: 0.8012 - val_accuracy: 0.6748\n",
            "Epoch 24/1024\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.9439\n",
            "Epoch 00024: Reducing Max LR on Plateau: new max lr will be 3.125e-06 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1654 - accuracy: 0.9439 - val_loss: 0.8009 - val_accuracy: 0.6699\n",
            "Epoch 25/1024\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1669 - accuracy: 0.9498 - val_loss: 0.8022 - val_accuracy: 0.6699\n",
            "Epoch 26/1024\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.1600 - accuracy: 0.9514\n",
            "Epoch 00026: Reducing Max LR on Plateau: new max lr will be 1.5625e-06 (if not early_stopping).\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1601 - accuracy: 0.9531 - val_loss: 0.8011 - val_accuracy: 0.6748\n",
            "Epoch 27/1024\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.1633 - accuracy: 0.9403Restoring model weights from the end of the best epoch: 22.\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1599 - accuracy: 0.9428 - val_loss: 0.8028 - val_accuracy: 0.6699\n",
            "Epoch 27: early stopping\n",
            "Weights from best epoch have been loaded into model.\n",
            "run 4 CORPUSNAME ljl class_names ['level1', 'level2', 'level3', 'level4']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      level1       0.53      0.42      0.47        24\n",
            "      level2       0.71      0.73      0.72        70\n",
            "      level3       0.69      0.72      0.70        67\n",
            "      level4       0.71      0.71      0.71        45\n",
            "\n",
            "    accuracy                           0.68       206\n",
            "   macro avg       0.66      0.64      0.65       206\n",
            "weighted avg       0.68      0.68      0.68       206\n",
            "\n",
            "-------------------------------------------------------------\n",
            "total run 4\n",
            "CORPUSNAME ljl\n",
            "{   'accuracy': 0.67,\n",
            "    'class_names': ['level1', 'level2', 'level3', 'level4'],\n",
            "    'data_name': 'ljl',\n",
            "    'false_neg': array([ 70, 107, 101,  67]),\n",
            "    'false_pos': array([ 59, 103, 118,  65]),\n",
            "    'fmeasure': array([0.44, 0.7 , 0.68, 0.71]),\n",
            "    'macro_avg_fmeasure': 0.63,\n",
            "    'macro_avg_precision': 0.63,\n",
            "    'macro_avg_recall': 0.63,\n",
            "    'precision': array([0.46, 0.7 , 0.66, 0.71]),\n",
            "    'recall': array([0.42, 0.69, 0.7 , 0.7 ]),\n",
            "    'support': array([120, 350, 335, 225]),\n",
            "    'total_support': 1030,\n",
            "    'true_pos': array([ 50, 243, 234, 158]),\n",
            "    'weighted_average_fmeasure': 0.66,\n",
            "    'weighted_average_precision': 0.66,\n",
            "    'weighted_average_recall': 0.67}\n",
            "(ljl) &\\multicolumn{3}{|c|}{level1}&\\multicolumn{3}{|c|}{level2}&\\multicolumn{3}{|c|}{level3}&\\multicolumn{3}{|c|}{level4}\\\\\n",
            "&P&\tR&\tF1&\tP&\tR&\tF1&\tP&\tR&\tF1&\tP&\tR&\tF1&\tAcc.&\tMacro avg.\\\\\n",
            "\t&0.46\t&0.42\t&0.44\t&0.7\t&0.69\t&0.7\t&0.66\t&0.7\t&0.68\t&0.71\t&0.7\t&0.71\t&0.67\t&0.63\\\\\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CamemBERT"
      ],
      "metadata": {
        "id": "X3SSrkCnLrgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This takes multiple hours without having enabled the GPU, remember to do this before:    \n",
        "Edit -> Notebook Settings -> Hardware Accelerator : GPU"
      ],
      "metadata": {
        "id": "Lb-3SwrVEWgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert.demo_doBert() #C an pass \"ljl\", \"bibebook.com\", \"JeLisLibre\", or \"all\" as a parameter\n",
        "#Takes around 15 minutes for the ljl corpus on GPU (default parameter)\n",
        "\n",
        "#FIXME : same reason as for fasttext, not a true cross-validation."
      ],
      "metadata": {
        "id": "mRRUtxGQwFwC",
        "outputId": "0f10ca42-8dea-48b0-bf1b-ae5797aaa5b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n",
            "['id', 'text', 'level1', 'level2', 'level3', 'level4']\n",
            "len_train 1854\n",
            "CORPUS_NAME ljl MODEL_NAME camembert-base class_names ['level1', 'level2', 'level3', 'level4']\n",
            "--> getTransformer\n",
            "preprocessing train...\n",
            "language: fr\n",
            "train sequence lengths:\n",
            "\tmean : 195\n",
            "\t95percentile : 424\n",
            "\t99percentile : 608\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: fr\n",
            "test sequence lengths:\n",
            "\tmean : 178\n",
            "\t95percentile : 389\n",
            "\t99percentile : 495\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t <class 'ktrain.text.preprocessor.Transformer'> \n",
            "trn <class 'ktrain.text.dataset.TransformerDataset'> \n",
            "val <class 'ktrain.text.dataset.TransformerDataset'> \n",
            "model <class 'transformers.models.camembert.modeling_tf_camembert.TFCamembertForSequenceClassification'> \n",
            "learner <class 'ktrain.text.learner.TransformerTextClassLearner'>\n",
            "Model: \"tf_camembert_for_sequence_classification_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " roberta (TFRobertaMainLayer  multiple                 110031360 \n",
            " )                                                               \n",
            "                                                                 \n",
            " classifier (TFRobertaClassi  multiple                 593668    \n",
            " ficationHead)                                                   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 110,625,028\n",
            "Trainable params: 110,625,028\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "-------------------------------------------------------run 0\n",
            "early_stopping automatically enabled at patience=5\n",
            "reduce_on_plateau automatically enabled at patience=2\n",
            "\n",
            "\n",
            "begin training using triangular learning rate policy with max lr of 0.0001...\n",
            "Epoch 1/1024\n",
            "309/309 [==============================] - 79s 206ms/step - loss: 1.1892 - accuracy: 0.4239 - val_loss: 0.9923 - val_accuracy: 0.5194\n",
            "Epoch 2/1024\n",
            "309/309 [==============================] - 61s 196ms/step - loss: 0.9874 - accuracy: 0.5518 - val_loss: 0.8999 - val_accuracy: 0.5874\n",
            "Epoch 3/1024\n",
            "309/309 [==============================] - 61s 196ms/step - loss: 0.8045 - accuracy: 0.6634 - val_loss: 0.9214 - val_accuracy: 0.5437\n",
            "Epoch 4/1024\n",
            "309/309 [==============================] - ETA: 0s - loss: 0.6035 - accuracy: 0.7562\n",
            "Epoch 00004: Reducing Max LR on Plateau: new max lr will be 5e-05 (if not early_stopping).\n",
            "309/309 [==============================] - 61s 196ms/step - loss: 0.6035 - accuracy: 0.7562 - val_loss: 0.9046 - val_accuracy: 0.6117\n",
            "Epoch 5/1024\n",
            "309/309 [==============================] - 61s 196ms/step - loss: 0.3767 - accuracy: 0.8695 - val_loss: 0.9320 - val_accuracy: 0.6505\n",
            "Epoch 6/1024\n",
            "309/309 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.9277\n",
            "Epoch 00006: Reducing Max LR on Plateau: new max lr will be 2.5e-05 (if not early_stopping).\n",
            "309/309 [==============================] - 61s 196ms/step - loss: 0.2250 - accuracy: 0.9277 - val_loss: 1.1205 - val_accuracy: 0.6602\n",
            "Epoch 7/1024\n",
            "309/309 [==============================] - ETA: 0s - loss: 0.1163 - accuracy: 0.9693Restoring model weights from the end of the best epoch: 2.\n",
            "309/309 [==============================] - 61s 196ms/step - loss: 0.1163 - accuracy: 0.9693 - val_loss: 1.1227 - val_accuracy: 0.6699\n",
            "Epoch 7: early stopping\n",
            "Weights from best epoch have been loaded into model.\n",
            "MODEL_NAME camembert-base run 0 CORPUSNAME ljl class_names ['level1', 'level2', 'level3', 'level4']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      level1       0.58      0.60      0.59        25\n",
            "      level2       0.61      0.65      0.63        65\n",
            "      level3       0.58      0.54      0.56        69\n",
            "      level4       0.57      0.57      0.57        47\n",
            "\n",
            "    accuracy                           0.59       206\n",
            "   macro avg       0.58      0.59      0.59       206\n",
            "weighted avg       0.59      0.59      0.59       206\n",
            "\n",
            "-------------------------------------------------------run 1\n",
            "early_stopping automatically enabled at patience=5\n",
            "reduce_on_plateau automatically enabled at patience=2\n",
            "\n",
            "\n",
            "begin training using triangular learning rate policy with max lr of 0.0001...\n",
            "Epoch 1/1024\n",
            "309/309 [==============================] - 62s 198ms/step - loss: 0.7535 - accuracy: 0.6936 - val_loss: 0.8861 - val_accuracy: 0.6165\n",
            "Epoch 2/1024\n",
            "309/309 [==============================] - 61s 198ms/step - loss: 0.5737 - accuracy: 0.7794 - val_loss: 0.7979 - val_accuracy: 0.6796\n",
            "Epoch 3/1024\n",
            "309/309 [==============================] - 61s 196ms/step - loss: 0.4618 - accuracy: 0.8258 - val_loss: 0.8358 - val_accuracy: 0.6796\n",
            "Epoch 4/1024\n",
            "309/309 [==============================] - 61s 196ms/step - loss: 0.4073 - accuracy: 0.8544 - val_loss: 0.7825 - val_accuracy: 0.7282\n",
            "Epoch 5/1024\n",
            "309/309 [==============================] - 61s 195ms/step - loss: 0.3042 - accuracy: 0.8900 - val_loss: 0.7895 - val_accuracy: 0.7184\n",
            "Epoch 6/1024\n",
            "309/309 [==============================] - ETA: 0s - loss: 0.2843 - accuracy: 0.8997\n",
            "Epoch 00006: Reducing Max LR on Plateau: new max lr will be 5e-05 (if not early_stopping).\n",
            "309/309 [==============================] - 61s 196ms/step - loss: 0.2843 - accuracy: 0.8997 - val_loss: 0.8614 - val_accuracy: 0.6990\n",
            "Epoch 7/1024\n",
            "309/309 [==============================] - 61s 196ms/step - loss: 0.1317 - accuracy: 0.9622 - val_loss: 0.9628 - val_accuracy: 0.7136\n",
            "Epoch 8/1024\n",
            "309/309 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9752\n",
            "Epoch 00008: Reducing Max LR on Plateau: new max lr will be 2.5e-05 (if not early_stopping).\n",
            "309/309 [==============================] - 61s 195ms/step - loss: 0.0841 - accuracy: 0.9752 - val_loss: 1.0433 - val_accuracy: 0.6990\n",
            "Epoch 9/1024\n",
            "309/309 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9887Restoring model weights from the end of the best epoch: 4.\n",
            "309/309 [==============================] - 61s 196ms/step - loss: 0.0489 - accuracy: 0.9887 - val_loss: 1.0381 - val_accuracy: 0.7427\n",
            "Epoch 9: early stopping\n",
            "Weights from best epoch have been loaded into model.\n",
            "MODEL_NAME camembert-base run 1 CORPUSNAME ljl class_names ['level1', 'level2', 'level3', 'level4']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      level1       0.75      0.36      0.49        25\n",
            "      level2       0.69      0.68      0.68        65\n",
            "      level3       0.69      0.84      0.76        69\n",
            "      level4       0.85      0.83      0.84        47\n",
            "\n",
            "    accuracy                           0.73       206\n",
            "   macro avg       0.74      0.68      0.69       206\n",
            "weighted avg       0.73      0.73      0.72       206\n",
            "\n",
            "{   'accuracy': 0.66,\n",
            "    'class_names': ['level1', 'level2', 'level3', 'level4'],\n",
            "    'data_name': 'ljl',\n",
            "    'false_neg': array([26, 44, 43, 28]),\n",
            "    'false_pos': array([14, 47, 53, 27]),\n",
            "    'fmeasure': array([0.55, 0.65, 0.66, 0.71]),\n",
            "    'macro_avg_fmeasure': 0.64,\n",
            "    'macro_avg_precision': 0.66,\n",
            "    'macro_avg_recall': 0.63,\n",
            "    'precision': array([0.63, 0.65, 0.64, 0.71]),\n",
            "    'recall': array([0.48, 0.66, 0.69, 0.7 ]),\n",
            "    'support': array([ 50, 130, 138,  94]),\n",
            "    'total_support': 412,\n",
            "    'true_pos': array([24, 86, 95, 66]),\n",
            "    'weighted_average_fmeasure': 0.66,\n",
            "    'weighted_average_precision': 0.66,\n",
            "    'weighted_average_recall': 0.66}\n",
            "-------------------------------------------------------------\n",
            "total run 1 MODEL_NAME camembert-base\n",
            "CORPUSNAME ljl CORPUSNAME ljl\n",
            "{   'accuracy': 0.66,\n",
            "    'class_names': ['level1', 'level2', 'level3', 'level4'],\n",
            "    'data_name': 'ljl',\n",
            "    'false_neg': array([26, 44, 43, 28]),\n",
            "    'false_pos': array([14, 47, 53, 27]),\n",
            "    'fmeasure': array([0.55, 0.65, 0.66, 0.71]),\n",
            "    'macro_avg_fmeasure': 0.64,\n",
            "    'macro_avg_precision': 0.66,\n",
            "    'macro_avg_recall': 0.63,\n",
            "    'precision': array([0.63, 0.65, 0.64, 0.71]),\n",
            "    'recall': array([0.48, 0.66, 0.69, 0.7 ]),\n",
            "    'support': array([ 50, 130, 138,  94]),\n",
            "    'total_support': 412,\n",
            "    'true_pos': array([24, 86, 95, 66]),\n",
            "    'weighted_average_fmeasure': 0.66,\n",
            "    'weighted_average_precision': 0.66,\n",
            "    'weighted_average_recall': 0.66}\n",
            "(ljl) &\\multicolumn{3}{|c|}{level1}&\\multicolumn{3}{|c|}{level2}&\\multicolumn{3}{|c|}{level3}&\\multicolumn{3}{|c|}{level4}\\\\\n",
            "&P&\tR&\tF1&\tP&\tR&\tF1&\tP&\tR&\tF1&\tP&\tR&\tF1&\tAcc.&\tMacro avg.\\\\\n",
            "\t&0.63\t&0.48\t&0.55\t&0.66\t&0.65\t&0.66\t&0.65\t&0.66\t&0.64\t&0.69\t&0.66\t&0.66\t&0.71\t&0.7\t&0.71\t&0.66\t&0.64\\\\\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examples of use"
      ],
      "metadata": {
        "id": "BJDUhalJXG-V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO5yJj1MLyFO"
      },
      "source": [
        "## Importing data for the examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fOKIaEKfLyFP"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(os.path.join(os.getcwd(),\"data\",\"tokens_split.pkl\"), \"rb\") as file:\n",
        "    corpus = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This can also be done by doing a wget :\n",
        "#!wget -nc https://github.com/nicolashernandez/READI-LREC22/blob/main/data/tokens_split.pkl?raw=true -P data\n",
        "#with open(os.path.join(os.getcwd(),\"data\",\"tokens_split.pkl?raw=true\"), \"rb\") as file:\n",
        "#    corpus = pickle.load(file)"
      ],
      "metadata": {
        "id": "s8YEy-XhWqur"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apwsw5v2LyFP"
      },
      "source": [
        "## Example one : Using the library for a text\n",
        "\n",
        "Texts can be strings, but it is preferred to prepare them beforehand as tokenized sentences. ( list(list()) )  \n",
        "If using spacy, something like this can be used :  \n",
        "new_text = [[token.text for token in sent] for sent in spacy(text).sents]  \n",
        "And to remove punctuation marks, this can be done instead :  \n",
        "new_text = [[token.text for token in sent if not token.is_punct] for sent in spacy(temp).sents]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgaAcEHLLyFS"
      },
      "source": [
        "A readability instance is created by calling readability.Readability(text)  \n",
        "The following arguments are optional : lang, nlp_name, perplexity_processor  \n",
        "By default, this instance will use the french language, by using a spacy_sm nlp processor, and gpt2 for processing perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-fNjDrEgLyFT",
        "outputId": "2320c9f8-d110-4c39-a5bd-8d50c95720e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acquiring Natural Language Processor...\n",
            "DEBUG: Spacy model location (already installed) :  /usr/local/lib/python3.7/dist-packages/fr_core_news_sm/fr_core_news_sm-2.2.5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "#Types of available formats for a text:\n",
        "r = readability.Readability(corpus['level1'][0]) # A text in the list(list()) format used internally\n",
        "#r = readability.Readability(' '.join(corpus['level1'][0][0])) # A string, it will be converted into a list(list()), of size 1, with 12 tokens, including punctuation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCznBc_8LyFU"
      },
      "source": [
        "Common scores can be accessed by using the corresponding function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XEJK_MYOLyFU",
        "outputId": "be67682f-31e8-4056-f2a7-c43c1f2c05e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61.52380952380953"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "gfi = r.gfi()\n",
        "gfi #is 61.52380952380953"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLsDXGXrLyFV"
      },
      "source": [
        "More conveniently, a list of these scores can be obtained by using .scores()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EqHKydKmLyFW",
        "outputId": "a1cfd688-08cb-4913-fe1d-a935f0ba259b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ari': 21.503161490683233,\n",
              " 'fkgl': 8.382298136645964,\n",
              " 'fre': 54.47311594202901,\n",
              " 'gfi': 61.52380952380953,\n",
              " 'rel': 73.00333333333334,\n",
              " 'smog': 13.023866798666859}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "r.scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RsaWHmrLyFW"
      },
      "source": [
        "In order to speed the calculations needed by these functions, the .compile() function can be used.  \n",
        "It calculates most of the statistics needed for a text, and puts it in the .statistics attribute of the Readability object.  \n",
        "These can be viewed by doing .stats(), or directly accessing the .statistics attribute.  \n",
        "For example : .statistics.totalWords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3iNUbMcOLyFW",
        "outputId": "d6346f73-8e7c-44a2-cf8e-9bd430025b41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "totalWords = 230\n",
            "totalLongWords = 30\n",
            "totalSentences = 21\n",
            "totalCharacters = 837\n",
            "totalSyllables = 384\n",
            "nbPolysyllables = 63\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "230"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "r.compile()\n",
        "r.stats()\n",
        "r.statistics.totalWords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeG9xrv1LyFX"
      },
      "source": [
        "## Example two : Using the library for a corpus\n",
        "\n",
        "Currently, a corpus will be recognized by the library only if provided with the following structure :  \n",
        "type(corpus) = dict[class][text][sentence][token]  \n",
        "For instance, corpA['class1'][0][0][0] should return the first token of the first sentence of the first text of class 'class1', for the corpus 'corpA'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ja15sx79LyFX",
        "outputId": "c389a3bf-1385-45eb-95ac-f5810219e86e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acquiring Natural Language Processor...\n",
            "DEBUG: Spacy model location (already installed) :  /usr/local/lib/python3.7/dist-packages/fr_core_news_sm/fr_core_news_sm-2.2.5\n"
          ]
        }
      ],
      "source": [
        "r = readability.Readability(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-dg0de3LyFY"
      },
      "source": [
        "A useful function resuming the contents of the corpus is available, called .corpus_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TKII3iNjLyFY",
        "outputId": "c6042927-946e-47d9-d2c9-150ece2c006a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                level1    level2    level3    level4     total\n",
              "Nombre de fichiers               240.0     628.0     670.0     522.0    2060.0\n",
              "Nombre de phrases total         4880.0   13049.0   10354.0    7743.0   36026.0\n",
              "Nombre de phrases moyen           20.0      21.0      15.0      15.0      17.0\n",
              "Longueur moyenne de phrase         8.0      10.0      12.0      13.0      11.0\n",
              "Nombre de tokens               38976.0  128019.0  124901.0  101165.0  393061.0\n",
              "Nombre de token moyen            162.0     204.0     186.0     194.0     191.0\n",
              "Taille du vocabulaire           4836.0   10903.0   11953.0   11410.0   23100.0\n",
              "Taille moyenne du vocabulaire     99.0     130.0     127.0     149.0    2257.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0ffa3bf-747a-4329-94d4-8cf2e3eca24c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level1</th>\n",
              "      <th>level2</th>\n",
              "      <th>level3</th>\n",
              "      <th>level4</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Nombre de fichiers</th>\n",
              "      <td>240.0</td>\n",
              "      <td>628.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>522.0</td>\n",
              "      <td>2060.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nombre de phrases total</th>\n",
              "      <td>4880.0</td>\n",
              "      <td>13049.0</td>\n",
              "      <td>10354.0</td>\n",
              "      <td>7743.0</td>\n",
              "      <td>36026.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nombre de phrases moyen</th>\n",
              "      <td>20.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Longueur moyenne de phrase</th>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nombre de tokens</th>\n",
              "      <td>38976.0</td>\n",
              "      <td>128019.0</td>\n",
              "      <td>124901.0</td>\n",
              "      <td>101165.0</td>\n",
              "      <td>393061.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nombre de token moyen</th>\n",
              "      <td>162.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>191.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Taille du vocabulaire</th>\n",
              "      <td>4836.0</td>\n",
              "      <td>10903.0</td>\n",
              "      <td>11953.0</td>\n",
              "      <td>11410.0</td>\n",
              "      <td>23100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Taille moyenne du vocabulaire</th>\n",
              "      <td>99.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>2257.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0ffa3bf-747a-4329-94d4-8cf2e3eca24c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0ffa3bf-747a-4329-94d4-8cf2e3eca24c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0ffa3bf-747a-4329-94d4-8cf2e3eca24c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "r.corpus_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MptkioiALyFY"
      },
      "source": [
        "When using a corpus, the Readability object's methods can return different types of results, but the behavior is similar:  \n",
        "Instead of returning a value, or a list, the methods may return them in a dict[class][text_index] format.  \n",
        "Additionally, .compile() will create the .corpus_statistics attribute instead of .statistics.  \n",
        ".stats() will print the statistics of the first text in each class, in addition to showing the mean values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NABoz6OsLyFZ",
        "outputId": "9fafe3d4-758e-4083-b5fa-e0a9dcc5aee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class level1\n",
            "totalWords = 230\n",
            "totalLongWords = 30\n",
            "totalSentences = 21\n",
            "totalCharacters = 837\n",
            "totalSyllables = 384\n",
            "nbPolysyllables = 63\n",
            "Class level2\n",
            "totalWords = 138\n",
            "totalLongWords = 26\n",
            "totalSentences = 8\n",
            "totalCharacters = 555\n",
            "totalSyllables = 240\n",
            "nbPolysyllables = 43\n",
            "Class level3\n",
            "totalWords = 104\n",
            "totalLongWords = 16\n",
            "totalSentences = 11\n",
            "totalCharacters = 405\n",
            "totalSyllables = 184\n",
            "nbPolysyllables = 21\n",
            "Class level4\n",
            "totalWords = 567\n",
            "totalLongWords = 112\n",
            "totalSentences = 35\n",
            "totalCharacters = 2307\n",
            "totalSyllables = 972\n",
            "nbPolysyllables = 151\n"
          ]
        }
      ],
      "source": [
        "r.compile()\n",
        "r.stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aC4P0miCLyFZ",
        "outputId": "b20ffc21-d076-4133-ed68-290cc8e4d1a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class level1 text 0 score 61.52380952380953\n",
            "class level2 text 0 score 136.9\n",
            "class level3 text 0 score 61.963636363636375\n",
            "class level4 text 0 score 134.48\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61.52380952380953"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "gfi_corp = r.gfi()\n",
        "gfi_corp['level1'][0] #Is also 61.52380952380953"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeZFhG7cLyFa"
      },
      "source": [
        "r.scores behaves differently, instead of giving the scores for each text, it returns a dataframe showing the mean values, (and prints out the standard deviation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vod9d0HBLyFa",
        "outputId": "49345470-b14b-4aa6-fa86-38315b9c7446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard Deviation values                   level1     level2     level3  \\\n",
            "The Gunning fog index GFI                22.638448  28.598931  38.724814   \n",
            "The Automated readability index ARI       6.265479   6.977522   8.614690   \n",
            "The Flesch reading ease FRE              26.013539  24.790444  29.308209   \n",
            "The Flesch-Kincaid grade level FKGL       3.386159   2.447647   2.501191   \n",
            "The Simple Measure of Gobbledygook SMOG   1.728092   1.647957   1.839104   \n",
            "Reading Ease Level                       19.108738  12.993784  12.457079   \n",
            "\n",
            "Standard Deviation values                   level4  \n",
            "The Gunning fog index GFI                45.192761  \n",
            "The Automated readability index ARI       9.156945  \n",
            "The Flesch reading ease FRE              32.117630  \n",
            "The Flesch-Kincaid grade level FKGL       2.833996  \n",
            "The Simple Measure of Gobbledygook SMOG   1.978900  \n",
            "Reading Ease Level                       14.318104  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mean values                                 level1     level2     level3  \\\n",
              "The Gunning fog index GFI                45.132518  67.697721  91.866336   \n",
              "The Automated readability index ARI      14.238996  19.932585  25.719148   \n",
              "The Flesch reading ease FRE              90.625507  84.875840  82.799719   \n",
              "The Flesch-Kincaid grade level FKGL       4.576800   6.681592   8.323094   \n",
              "The Simple Measure of Gobbledygook SMOG  10.110286  11.521299  12.760749   \n",
              "Reading Ease Level                       92.465376  82.239781  75.110005   \n",
              "\n",
              "Mean values                                  level4  Pearson Score  \n",
              "The Gunning fog index GFI                105.669951       0.475915  \n",
              "The Automated readability index ARI       27.757700       0.472037  \n",
              "The Flesch reading ease FRE               81.032160      -0.402143  \n",
              "The Flesch-Kincaid grade level FKGL        9.019000       0.451786  \n",
              "The Simple Measure of Gobbledygook SMOG   13.210278       0.471106  \n",
              "Reading Ease Level                        71.711107      -0.408414  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-715c5c65-a919-4a11-94b3-51d2b1834436\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Mean values</th>\n",
              "      <th>level1</th>\n",
              "      <th>level2</th>\n",
              "      <th>level3</th>\n",
              "      <th>level4</th>\n",
              "      <th>Pearson Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>The Gunning fog index GFI</th>\n",
              "      <td>45.132518</td>\n",
              "      <td>67.697721</td>\n",
              "      <td>91.866336</td>\n",
              "      <td>105.669951</td>\n",
              "      <td>0.475915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>The Automated readability index ARI</th>\n",
              "      <td>14.238996</td>\n",
              "      <td>19.932585</td>\n",
              "      <td>25.719148</td>\n",
              "      <td>27.757700</td>\n",
              "      <td>0.472037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>The Flesch reading ease FRE</th>\n",
              "      <td>90.625507</td>\n",
              "      <td>84.875840</td>\n",
              "      <td>82.799719</td>\n",
              "      <td>81.032160</td>\n",
              "      <td>-0.402143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>The Flesch-Kincaid grade level FKGL</th>\n",
              "      <td>4.576800</td>\n",
              "      <td>6.681592</td>\n",
              "      <td>8.323094</td>\n",
              "      <td>9.019000</td>\n",
              "      <td>0.451786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>The Simple Measure of Gobbledygook SMOG</th>\n",
              "      <td>10.110286</td>\n",
              "      <td>11.521299</td>\n",
              "      <td>12.760749</td>\n",
              "      <td>13.210278</td>\n",
              "      <td>0.471106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reading Ease Level</th>\n",
              "      <td>92.465376</td>\n",
              "      <td>82.239781</td>\n",
              "      <td>75.110005</td>\n",
              "      <td>71.711107</td>\n",
              "      <td>-0.408414</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-715c5c65-a919-4a11-94b3-51d2b1834436')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-715c5c65-a919-4a11-94b3-51d2b1834436 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-715c5c65-a919-4a11-94b3-51d2b1834436');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "r.scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSxHqGW5LyFb"
      },
      "source": [
        "In addition, machine learning and deep learning applications can be used with the corpus' data to help develop NLP solutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE73FO2zLyFb"
      },
      "outputs": [],
      "source": [
        "#r.importmodel(camembert)\n",
        "#r.configmodel(params)\n",
        "#r.train(mode=autofit)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "0d8382c64f832ccbfeaab2a5edd229bc484a8f789774f43ccfafc2e4aa4ca7e5"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "readi_reproduction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}