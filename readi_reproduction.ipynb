{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolashernandez/READI-LREC22/blob/main/readi_reproduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6OK4ukoLyFI"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook comes from the git repository available [here](https://github.com/nicolashernandez/READI-LREC22/)  \n",
        "The following examples will show how this library can be used and configured.  \n",
        "It'll later be ported to colab, this is a version that works on your computer as long as the library has been installed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRRW2zl5LyFL"
      },
      "source": [
        "# Setup : import library and data from repository"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "N27YcpQvUN39"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Download project and set current directory\n",
        "!git clone https://github.com/nicolashernandez/READI-LREC22/\n",
        "%cd READI-LREC22/"
      ],
      "metadata": {
        "id": "jDdveq3ZUI__",
        "outputId": "f302ccaa-84e2-4574-86c9-229325c20a24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'READI-LREC22'...\n",
            "remote: Enumerating objects: 172, done.\u001b[K\n",
            "remote: Counting objects: 100% (172/172), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 172 (delta 80), reused 132 (delta 47), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (172/172), 8.64 MiB | 10.73 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# 2. Install module\n",
        "!pip install ."
      ],
      "metadata": {
        "id": "Z_XksS_gUJOQ",
        "outputId": "e931f443-9278-4e20-a147-5298766e6b7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/READI-LREC22\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from readability-TristanFaine==0.0.9) (1.11.0+cu113)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from readability-TristanFaine==0.0.9) (1.4.1)\n",
            "Requirement already satisfied: spacy<4.0.0,>3.0.0 in /usr/local/lib/python3.7/dist-packages (from readability-TristanFaine==0.0.9) (3.3.1)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (from readability-TristanFaine==0.0.9) (1.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from readability-TristanFaine==0.0.9) (1.3.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from readability-TristanFaine==0.0.9) (4.19.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (2.4.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (4.1.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (1.0.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (4.64.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (0.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (3.0.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (3.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (2.23.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (8.0.17)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (0.6.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (0.4.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (1.8.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (3.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (2.0.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (1.21.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (2022.5.18.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4.0.0,>3.0.0->readability-TristanFaine==0.0.9) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->readability-TristanFaine==0.0.9) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->readability-TristanFaine==0.0.9) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->readability-TristanFaine==0.0.9) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->readability-TristanFaine==0.0.9) (3.7.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->readability-TristanFaine==0.0.9) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->readability-TristanFaine==0.0.9) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->readability-TristanFaine==0.0.9) (4.11.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers->readability-TristanFaine==0.0.9) (0.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers->readability-TristanFaine==0.0.9) (6.0)\n",
            "Building wheels for collected packages: readability-TristanFaine\n",
            "  Building wheel for readability-TristanFaine (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for readability-TristanFaine: filename=readability_TristanFaine-0.0.9-py3-none-any.whl size=2332 sha256=bdc44f2b4b8ee64e1316040371f21d2e3ea4a04254085289f8a09619f92a5d00\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/97/a7/8d6249879d64d408870a262a0230855b84b2e5d5da4190b4d5\n",
            "Successfully built readability-TristanFaine\n",
            "Installing collected packages: readability-TristanFaine\n",
            "  Attempting uninstall: readability-TristanFaine\n",
            "    Found existing installation: readability-TristanFaine 0.0.9\n",
            "    Uninstalling readability-TristanFaine-0.0.9:\n",
            "      Successfully uninstalled readability-TristanFaine-0.0.9\n",
            "Successfully installed readability-TristanFaine-0.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "id": "AdTtIaVvUtfu",
        "outputId": "08fffc95-bc9c-40e9-ecf5-1db2db86a6a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/READI-LREC22'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. put the path or something\n",
        "import sys,os\n",
        "sys.path.append(os.getcwd())\n",
        "#sys.path.append(os.path.join(os.getcwd(),\"readability\"))"
      ],
      "metadata": {
        "id": "y_GOTUVpUJb8"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "1dlJDld-LyFO"
      },
      "outputs": [],
      "source": [
        "import readability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO5yJj1MLyFO"
      },
      "source": [
        "# Recreating the contents of the paper"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recreating the content of the paper, experiment by experiment :"
      ],
      "metadata": {
        "id": "v3Ft-YbkW5pc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "fOKIaEKfLyFP"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "#FIXME : replace this with a wget to the git directory\n",
        "with open(os.path.join(os.getcwd(),\"data\",\"tokens_split.pkl\"), \"rb\") as file:\n",
        "    corpus = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This can also be done by doing a wget :\n",
        "#!wget -nc https://github.com/nicolashernandez/READI-LREC22/blob/main/data/tokens_split.pkl?raw=true -P data\n",
        "#with open(os.path.join(os.getcwd(),\"data\",\"tokens_split.pkl?raw=true\"), \"rb\") as file:\n",
        "#    corpus = pickle.load(file)"
      ],
      "metadata": {
        "id": "s8YEy-XhWqur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examples of use"
      ],
      "metadata": {
        "id": "BJDUhalJXG-V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apwsw5v2LyFP"
      },
      "source": [
        "## Example one : Using the library for a text\n",
        "\n",
        "Texts can be strings, but it is preferred to prepare them beforehand as tokenized sentences. ( list(list()) )  \n",
        "If using spacy, something like this can be used :  \n",
        "new_text = [[token.text for token in sent] for sent in spacy(text).sents]  \n",
        "And to remove punctuation marks, this can be done instead :  \n",
        "new_text = [[token.text for token in sent if not token.is_punct] for sent in spacy(temp).sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3vj6oxjLyFQ",
        "outputId": "8de25bc0-a181-4729-c513-2abdb47b8842"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'readability' from '/home/stagiaire-taln/Stage_repo_git/READI-LREC22/library/readability/__init__.py'>"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import importlib\n",
        "importlib.reload(readability.readability)\n",
        "importlib.reload(readability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgaAcEHLLyFS"
      },
      "source": [
        "A readability instance is created by calling readability.Readability(text)  \n",
        "The following arguments are optional : lang, nlp_name, perplexity_processor  \n",
        "By default, this instance will use the french language, by using a spacy_sm nlp processor, and gpt2 for processing perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fNjDrEgLyFT",
        "outputId": "a4977ef3-bf3f-4670-d81e-f9076e58b131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG : Current parameters of Readability class : lang= fr nlp= spacy_sm ppl_processor= gpt2\n",
            "Acquiring Natural Language Processor...\n",
            "DEBUG: Spacy model location (already installed) :  /home/stagiaire-taln/anaconda3/lib/python3.9/site-packages/fr_core_news_sm/fr_core_news_sm-3.3.0\n",
            "DEBUG : Text recognized as list of sentences, not converting\n",
            "DEBUG: recognized content is : [[\"Aujourd'hui\", ',', 'toute', 'la', 'famille', 'est', 'allée', 'à', 'la', 'fête', 'foraine', '.'], ['Papa', 'a', 'acheté', 'à', 'mon', 'frère', 'des', 'lunettes', 'amusantes', '.'], ['Maman', \"m'\", 'a', 'acheté', 'une', 'très', 'belle', 'casquette', 'bleue', '.'], ['Ma', 'petite', 'sœur', ',', 'elle', ',', 'a', 'eu', 'un', 'suçon', '.'], ['En', 'revenant', 'à', 'la', 'maison', ',', 'un', 'très', 'gros', 'coup', 'de', 'vent', 'a', 'emporté', 'ma', 'casquette', '.'], ['Ma', 'casquette', 'est', 'allée', 'se', 'poser', 'sur', 'la', 'branche', \"d'\", 'un', 'vieil', 'arbre', 'énorme', '.'], [\"J'\", 'ai', 'beaucoup', 'pleuré', '.'], [\"J'\", 'ai', 'même', 'refusé', 'de', 'manger', 'pour', 'le', 'souper', '.'], ['Plus', 'tard', 'en', 'soirée', ',', 'la', 'lune', 'a', 'fait', 'son', 'apparition', '.'], [\"J'\", 'avais', \"l'\", 'impression', \"qu'\", 'elle', 'regardait', 'ma', 'casquette', 'dans', 'le', 'vieil', 'arbre', '.'], ['La', 'lune', 'a', 'essayé', 'ma', 'casquette', 'et', 'elle', 'a', 'souri', '.'], [\"J'\", 'ai', 'souri', 'aussi', '.'], ['Le', 'lendemain', ',', 'au', 'retour', 'de', \"l'\", 'école', ',', 'ma', 'mère', \"m'\", 'a', 'donné', 'une', 'nouvelle', 'casquette', ',', 'mais', 'rouge', '.'], ['Elle', 'était', 'magnifique', '!', '\"'], ['La', 'lune', \"t'\", 'a', 'envoyé', \"t'\", 'a', 'envoyé', 'ceci', '.'], [\"m'\", 'a', '-', 't', '-', 'elle', 'dit', '.'], ['Ce', 'soir', '-', 'là', ',', 'je', 'suis', 'sorti', 'avec', 'ma', 'nouvelle', 'casquette', '.'], ['La', 'lune', 'était', 'là', ',', 'coiffée', 'de', 'ma', 'casquette', 'bleue', '.'], [\"J'\", 'étais', 'heureux', '.'], ['Est', '-ce', 'que', 'tu', 'crois', 'que', 'le', 'soleil', 'aurait', 'besoin', \"d'\", 'une', 'casquette', 'lui', 'aussi', '?'], ['Essaie', 'de', 'deviner', 'le', 'chapeau', 'que', 'je', 'porte', 'aujourd’hui', '!']]\n"
          ]
        }
      ],
      "source": [
        "#Types of available formats for a text:\n",
        "r = readability.Readability(corpus['level1'][0]) # A text in the list(list()) format used internally\n",
        "#r = readability.Readability(' '.join(corpus['level1'][0][0])) # A string, it will be converted into a list(list()), of size 1, with 12 tokens, including punctuation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCznBc_8LyFU"
      },
      "source": [
        "Common scores can be accessed by using the corresponding function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEJK_MYOLyFU",
        "outputId": "9354c547-1267-4c66-b8d6-bbb0c58defff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG : pre-existing information was not found, so the .gfi_score() function should determine it by itself\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "61.52380952380953"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gfi = r.gfi()\n",
        "gfi #is 61.52380952380953"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLsDXGXrLyFV"
      },
      "source": [
        "More conveniently, a list of these scores can be obtained by using .scores()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqHKydKmLyFW",
        "outputId": "99a93509-05bc-407d-f2ca-ce9f5d7b3676"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG : pre-existing information was not found, so the .gfi_score() function should determine it by itself\n",
            "DEBUG : pre-existing information was not found, so the .ari_score() function should determine it by itself\n",
            "DEBUG : pre-existing information was not found, so the .fre_score() function should determine it by itself\n",
            "DEBUG : pre-existing information was not found, so the .fkgl_score() function should determine it by itself\n",
            "DEBUG : pre-existing information was not found, so the .smog_score() function should determine it by itself\n",
            "DEBUG : pre-existing information was not found, so the .rel_score() function should determine it by itself\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'gfi': 61.52380952380953,\n",
              " 'ari': 21.503161490683233,\n",
              " 'fre': 54.47311594202901,\n",
              " 'fkgl': 8.382298136645964,\n",
              " 'smog': 13.023866798666859,\n",
              " 'rel': 73.00333333333334}"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r.scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RsaWHmrLyFW"
      },
      "source": [
        "In order to speed the calculations needed by these functions, the .compile() function can be used.  \n",
        "It calculates most of the statistics needed for a text, and puts it in the .statistics attribute of the Readability object.  \n",
        "These can be viewed by doing .stats(), or directly accessing the .statistics attribute.  \n",
        "For example : .statistics.totalWords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iNUbMcOLyFW",
        "outputId": "42e69453-49d1-4e61-9e2b-27eddbeff88e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "totalWords  =  230\n",
            "totalLongWords  =  30\n",
            "totalSentences  =  21\n",
            "totalCharacters  =  837\n",
            "totalSyllables  =  384\n",
            "nbPolysyllables  =  63\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "230"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r.compile()\n",
        "r.stats()\n",
        "r.statistics.totalWords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeG9xrv1LyFX"
      },
      "source": [
        "## Example two : Using the library for a corpus\n",
        "\n",
        "Currently, a corpus will be recognized by the library only if provided with the following structure :  \n",
        "type(corpus) = dict[class][text][sentence][token]  \n",
        "For instance, corpA['class1'][0][0][0] should return the first token of the first sentence of the first text of class 'class1', for the corpus 'corpA'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja15sx79LyFX",
        "outputId": "5502d3f6-86d4-4daa-d181-e74b66b25452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG : Current parameters of Readability class : lang= fr nlp= spacy_sm ppl_processor= gpt2\n",
            "Acquiring Natural Language Processor...\n",
            "DEBUG: Spacy model location (already installed) :  /home/stagiaire-taln/anaconda3/lib/python3.9/site-packages/fr_core_news_sm/fr_core_news_sm-3.3.0\n",
            "DEBUG : recognized as corpus\n"
          ]
        }
      ],
      "source": [
        "r = readability.Readability(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-dg0de3LyFY"
      },
      "source": [
        "A useful function resuming the contents of the corpus is available, called .corpus_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKII3iNjLyFY",
        "outputId": "ea8cda5d-9d55-417e-91b4-6ec1d6f368e4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level1</th>\n",
              "      <th>level2</th>\n",
              "      <th>level3</th>\n",
              "      <th>level4</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Nombre de fichiers</th>\n",
              "      <td>240.0</td>\n",
              "      <td>628.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>522.0</td>\n",
              "      <td>2060.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nombre de phrases total</th>\n",
              "      <td>4880.0</td>\n",
              "      <td>13049.0</td>\n",
              "      <td>10354.0</td>\n",
              "      <td>7743.0</td>\n",
              "      <td>36026.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nombre de phrases moyen</th>\n",
              "      <td>20.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Longueur moyenne de phrase</th>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nombre de tokens</th>\n",
              "      <td>38976.0</td>\n",
              "      <td>128019.0</td>\n",
              "      <td>124901.0</td>\n",
              "      <td>101165.0</td>\n",
              "      <td>393061.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nombre de token moyen</th>\n",
              "      <td>162.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>191.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Taille du vocabulaire</th>\n",
              "      <td>4836.0</td>\n",
              "      <td>10903.0</td>\n",
              "      <td>11953.0</td>\n",
              "      <td>11410.0</td>\n",
              "      <td>23100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Taille moyenne du vocabulaire</th>\n",
              "      <td>99.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>2257.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                level1    level2    level3    level4     total\n",
              "Nombre de fichiers               240.0     628.0     670.0     522.0    2060.0\n",
              "Nombre de phrases total         4880.0   13049.0   10354.0    7743.0   36026.0\n",
              "Nombre de phrases moyen           20.0      21.0      15.0      15.0      17.0\n",
              "Longueur moyenne de phrase         8.0      10.0      12.0      13.0      11.0\n",
              "Nombre de tokens               38976.0  128019.0  124901.0  101165.0  393061.0\n",
              "Nombre de token moyen            162.0     204.0     186.0     194.0     191.0\n",
              "Taille du vocabulaire           4836.0   10903.0   11953.0   11410.0   23100.0\n",
              "Taille moyenne du vocabulaire     99.0     130.0     127.0     149.0    2257.0"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r.corpus_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MptkioiALyFY"
      },
      "source": [
        "When using a corpus, the Readability object's methods can return different types of results, but the behavior is similar:  \n",
        "Instead of returning a value, or a list, the methods may return them in a dict[class][text_index] format.  \n",
        "Additionally, .compile() will create the .corpus_statistics attribute instead of .statistics.  \n",
        ".stats() will print the statistics of the first text in each class, in addition to showing the mean values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NABoz6OsLyFZ",
        "outputId": "9d1a1d41-912e-48e7-af0c-03e29a684609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "finish r.compile() first\n",
            "Class level1\n",
            "totalWords  =  230\n",
            "Class level1\n",
            "totalLongWords  =  30\n",
            "Class level1\n",
            "totalSentences  =  21\n",
            "Class level1\n",
            "totalCharacters  =  837\n",
            "Class level1\n",
            "totalSyllables  =  384\n",
            "Class level1\n",
            "nbPolysyllables  =  63\n",
            "Class level2\n",
            "totalWords  =  138\n",
            "Class level2\n",
            "totalLongWords  =  26\n",
            "Class level2\n",
            "totalSentences  =  8\n",
            "Class level2\n",
            "totalCharacters  =  555\n",
            "Class level2\n",
            "totalSyllables  =  240\n",
            "Class level2\n",
            "nbPolysyllables  =  43\n",
            "Class level3\n",
            "totalWords  =  104\n",
            "Class level3\n",
            "totalLongWords  =  16\n",
            "Class level3\n",
            "totalSentences  =  11\n",
            "Class level3\n",
            "totalCharacters  =  405\n",
            "Class level3\n",
            "totalSyllables  =  184\n",
            "Class level3\n",
            "nbPolysyllables  =  21\n",
            "Class level4\n",
            "totalWords  =  567\n",
            "Class level4\n",
            "totalLongWords  =  112\n",
            "Class level4\n",
            "totalSentences  =  35\n",
            "Class level4\n",
            "totalCharacters  =  2307\n",
            "Class level4\n",
            "totalSyllables  =  972\n",
            "Class level4\n",
            "nbPolysyllables  =  151\n"
          ]
        }
      ],
      "source": [
        "r.compile()\n",
        "r.stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC4P0miCLyFZ",
        "outputId": "e255ca37-c3a0-4be1-8953-0a813db7ccae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG : pre-existing information was found for a corpus\n",
            "DEBUG : pre-existing information was found for a corpus\n",
            "DEBUG : pre-existing information was found for a corpus\n",
            "DEBUG : pre-existing information was found for a corpus\n",
            "class level1 text 0 score 61.52380952380953\n",
            "class level2 text 0 score 136.9\n",
            "class level3 text 0 score 61.963636363636375\n",
            "class level4 text 0 score 134.48\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "61.52380952380953"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gfi_corp = r.gfi()\n",
        "gfi_corp['level1'][0] #Is also 61.52380952380953"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeZFhG7cLyFa"
      },
      "source": [
        "r.scores behaves differently, instead of giving the scores for each text, it returns a dataframe showing the mean values, (and prints out the standard deviation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vod9d0HBLyFa",
        "outputId": "b4a04e51-09e8-4088-e2d1-68766916a09f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG : pre-existing information was found for a corpus\n",
            "Mean values                                 level1     level2     level3  \\\n",
            "The Gunning fog index GFI                45.132518  67.697721  91.866336   \n",
            "The Automated readability index ARI      14.238996  19.932585  25.719148   \n",
            "The Flesch reading ease FRE              90.625507  84.875840  82.799719   \n",
            "The Flesch-Kincaid grade level FKGL       4.576800   6.681592   8.323094   \n",
            "The Simple Measure of Gobbledygook SMOG  10.110286  11.521299  12.760749   \n",
            "Reading Ease Level                       92.465376  82.239781  75.110005   \n",
            "\n",
            "Mean values                                  level4  Pearson Score  \n",
            "The Gunning fog index GFI                105.669951       0.475915  \n",
            "The Automated readability index ARI       27.757700       0.472037  \n",
            "The Flesch reading ease FRE               81.032160      -0.402143  \n",
            "The Flesch-Kincaid grade level FKGL        9.019000       0.451786  \n",
            "The Simple Measure of Gobbledygook SMOG   13.210278       0.471106  \n",
            "Reading Ease Level                        71.711107      -0.408414  \n",
            "Standard Deviation values                   level1     level2     level3  \\\n",
            "The Gunning fog index GFI                22.638448  28.598931  38.724814   \n",
            "The Automated readability index ARI       6.265479   6.977522   8.614690   \n",
            "The Flesch reading ease FRE              26.013539  24.790444  29.308209   \n",
            "The Flesch-Kincaid grade level FKGL       3.386159   2.447647   2.501191   \n",
            "The Simple Measure of Gobbledygook SMOG   1.728092   1.647957   1.839104   \n",
            "Reading Ease Level                       19.108738  12.993784  12.457079   \n",
            "\n",
            "Standard Deviation values                   level4  \n",
            "The Gunning fog index GFI                45.192761  \n",
            "The Automated readability index ARI       9.156945  \n",
            "The Flesch reading ease FRE              32.117630  \n",
            "The Flesch-Kincaid grade level FKGL       2.833996  \n",
            "The Simple Measure of Gobbledygook SMOG   1.978900  \n",
            "Reading Ease Level                       14.318104  \n",
            "DEBUG: time elapsed perf counter: 0.025936164001905126\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Mean values</th>\n",
              "      <th>level1</th>\n",
              "      <th>level2</th>\n",
              "      <th>level3</th>\n",
              "      <th>level4</th>\n",
              "      <th>Pearson Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>The Gunning fog index GFI</th>\n",
              "      <td>45.132518</td>\n",
              "      <td>67.697721</td>\n",
              "      <td>91.866336</td>\n",
              "      <td>105.669951</td>\n",
              "      <td>0.475915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>The Automated readability index ARI</th>\n",
              "      <td>14.238996</td>\n",
              "      <td>19.932585</td>\n",
              "      <td>25.719148</td>\n",
              "      <td>27.757700</td>\n",
              "      <td>0.472037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>The Flesch reading ease FRE</th>\n",
              "      <td>90.625507</td>\n",
              "      <td>84.875840</td>\n",
              "      <td>82.799719</td>\n",
              "      <td>81.032160</td>\n",
              "      <td>-0.402143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>The Flesch-Kincaid grade level FKGL</th>\n",
              "      <td>4.576800</td>\n",
              "      <td>6.681592</td>\n",
              "      <td>8.323094</td>\n",
              "      <td>9.019000</td>\n",
              "      <td>0.451786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>The Simple Measure of Gobbledygook SMOG</th>\n",
              "      <td>10.110286</td>\n",
              "      <td>11.521299</td>\n",
              "      <td>12.760749</td>\n",
              "      <td>13.210278</td>\n",
              "      <td>0.471106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reading Ease Level</th>\n",
              "      <td>92.465376</td>\n",
              "      <td>82.239781</td>\n",
              "      <td>75.110005</td>\n",
              "      <td>71.711107</td>\n",
              "      <td>-0.408414</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Mean values                                 level1     level2     level3  \\\n",
              "The Gunning fog index GFI                45.132518  67.697721  91.866336   \n",
              "The Automated readability index ARI      14.238996  19.932585  25.719148   \n",
              "The Flesch reading ease FRE              90.625507  84.875840  82.799719   \n",
              "The Flesch-Kincaid grade level FKGL       4.576800   6.681592   8.323094   \n",
              "The Simple Measure of Gobbledygook SMOG  10.110286  11.521299  12.760749   \n",
              "Reading Ease Level                       92.465376  82.239781  75.110005   \n",
              "\n",
              "Mean values                                  level4  Pearson Score  \n",
              "The Gunning fog index GFI                105.669951       0.475915  \n",
              "The Automated readability index ARI       27.757700       0.472037  \n",
              "The Flesch reading ease FRE               81.032160      -0.402143  \n",
              "The Flesch-Kincaid grade level FKGL        9.019000       0.451786  \n",
              "The Simple Measure of Gobbledygook SMOG   13.210278       0.471106  \n",
              "Reading Ease Level                        71.711107      -0.408414  "
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r.scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSxHqGW5LyFb"
      },
      "source": [
        "In addition, machine learning and deep learning applications can be used with the corpus' data to help develop NLP solutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE73FO2zLyFb"
      },
      "outputs": [],
      "source": [
        "#r.importmodel(camembert)\n",
        "#r.train()"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "0d8382c64f832ccbfeaab2a5edd229bc484a8f789774f43ccfafc2e4aa4ca7e5"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "readi_reproduction.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}